\documentclass[11pt]{article}

\include{preamble}

\title{Portfolio Optimization in a Big Data Context}
\author{Thierry \textsc{Bazier-Matte} \and Erick \textsc{Delage}}

\begin{document}
\maketitle


The goal of this document is twofold. First, given a risk averse utility function and a
sample of the market observations (returns and states), we want to prescribe an optimal
linear investment policy depending on the risk aversion of the investor. Second, we also
wish to return to the investor probabilist bounds on the certainty equivalent of the
prescribed investment policy.

\section{Assumptions and Definitions}

In the following, $\bm A$ (capital boldface) are assumed to represent a real subset of any
dimension, $A$ (capital case) represents random variables (or distributions) and $a$
(lower case) represents deterministic variables or realizations. $\real$ represents the
real set.

Let $M=(X,R)$ the market be a random variable with support
$\bm M = \bm X\times \bm R \subseteq\real^{p+1}$, ie. numerically qualifiable, with
$(x,r) = m\sim M$ a market observation, consisting in one part state $x\in\real^p$ and
another part outcome $r\in\real$. Typically $x$ is a vector of observations from various
variable of interests, such as financial or economical news, etc. Scalar $r$ in this
article shall represent the return from a financial asset of interest. Finally, let
$M_n = \{M,\dots,M\}$ be a random set of $n$ (unrealized) observations (with support
$\bm M^n$). Therefore $\mu_n \sim M_n$ represents an iid sample of $n$ market
observations.

We shall study linear investment decisions $q\in\bm Q\subseteq\real^p$ such that $p=q^Tx$
part of the portfolio is allocated to the risky asset with return $r$, and $1-p$ part of
the portfolio is allocated to the riskless asset, providing a total return
$rp + R_f(1-p)$.
\begin{assumption}
  We suppose that observed returns $r$ are constrained by $|r| \leq \bar r$ and that
  observed states $x$ are constrained by $\|x\|_2 \leq \xMax$.
\end{assumption}

\begin{assumption}
  We also suppose that the investor's utility function $u$ is such that $u$ can be
  rescaled to a standard utility $\bar u$ with affine transformation
  $u(r) = k\bar u(r) + l$, where $k>0$ and $\bar u$ has the following properties:
  \begin{itemize}
  \item $\bar u$ is concave and non-decreasing;
  \item $\bar u$ is Lipschitz continuous, with constant $\gamma$, ie.
    $|\bar u(r_1) - \bar u(r_2)| \leq \gamma|r_1-r_2|$; \comment{Since random variables
      are bounded (Claims \ref{claim_q_bound} and \ref{claim_finite}), this assumption
      can be relaxed}
  \item $\bar u(0) = 0$;
  \item With representation
    $\bar u(x) = \bar u_-(x)\bm1_{\{x<0\}}+\bar u_+(x)\bm 1_{\{x\geq 0\}}$, we have
    $u_+(x) = o(u_-(x))$, ie. $\bar u_-$ dominates $\bar u_+$. \comment{Solve the
      Lipschitz contradiction.}
  \item $\lim_{r\to 0^{+}} \bar u'(r) = 1$ \comment{Necessary?}
  \end{itemize}

  An example of such a normalized utility is 
  \begin{equation*}
    \bar u(r) = \begin{cases}
      \beta^{-1}(1-e^{-\beta r}) & r > r_0\\
      re^{-\beta r_0} + \beta^{-1}(1-(1+\beta r_0)e^{-\beta r_0}) & r \leq r_0
    \end{cases}
  \end{equation*}
  with $\beta>0$. The else part is here to enforce the Lipschitz condition which is not
  respected on a standard exponential function. Other examples include piecewise linear
  functions.
\end{assumption}

\begin{deff}
  Let $\ell:\bm M\times \bm Q\to\real$ be a \textsl{loss function} defined by
  \begin{equation*}
    \ell(m,q) = \ell(x,r,q) = -u(r\,q^{T}x + R_f (1 - q^{T}x)),
  \end{equation*}
  where $R_f$ is the risk free return rate. We also define the \textsl{cost function}
  $c:\real\times\bm R\to\real$ as
  \begin{equation*}
    c(p,r) = -u(pr + (1-p)R_f),
  \end{equation*}
  so that $\ell(x,r,q) = c(q^Tx,r)$. 
\end{deff}

\begin{deff}
  The \textsl{empirical risk} $\hat R: \bm M^n\times \bm Q \to \real$ associated with decision
  $q$ and market sample $\mu_n$ is given by
 \begin{equation*}
   \hat R_{\mu_n}(q) = n^{-1} \sum_{i=1}^n \ell(m_i,q).
 \end{equation*}
\end{deff}

\begin{deff}
  The \textsl{empirical decision algorithm} $\hat A_n:\bm M^n \to \bm Q$ associated with
  market sample $\mu_n$ is the optimal value of the problem
  \begin{equation*}
    \text{minimize}\quad\hat R_{\mu_n}(q) + \lambda\|q\|_2^2.
  \end{equation*}
\end{deff}

From now on, as a notation shortcut, let $\hat q_n := \hat A_n(\mu_n)$ the empirical
decision associated with random market sample $\mu_n$ and $\hat R:=\hat R_{\mu_n}$ the
empirical risk.

\begin{deff}
  The \textsl{true risk} $R:\bm Q\to\real$ associated with decision $q$ is given by
  \begin{equation*}
    R(q) = \E[\ell(M,q)].
  \end{equation*}
\end{deff}

\begin{deff}
  The \textsl{true regularized risk} $R_\lambda:\bm Q\to\real$ associated with decision $q$
  is given by 
  \begin{equation*}
    R_\lambda(q) = \E[\ell(M,q)] + \lambda\|q\|^2_2.
  \end{equation*}
\end{deff}

\begin{deff}
  The \textsl{optimal decision} $\qStar$ is the optimal value of the problem
  \begin{equation*}
    \text{minimize}\quad R(q).
  \end{equation*}
\end{deff}

\begin{deff}
  The \textsl{optimal regularized decision} $q^\star_\lambda$ is the optimal value of the
  regularized problem 
  \begin{equation*}
        \text{minimize}\quad R_\lambda(q).
  \end{equation*}
\end{deff}


\section{Performance Bounds}

\subsection{Out of Sample Bound}

\begin{deff}
  A loss function $\ell$ is $\sigma$-admissible if its cost function $c$ is convex with
  respect to $p$ the investment decision and the following holds for any $p_1,p_2$ and
  $r$:
  \begin{equation*}
    |c(p_1,r) - c(p_2,r)| \leq \sigma|p_1-p_2|.
  \end{equation*}
\end{deff}

\begin{rem}
  The loss function as defined above is $\sigma$-admissible with $\sigma=k\gamma(r+R_f)$. See
  Claim \ref{claim0}.
\end{rem}

\begin{deff}
  Let $\hat q_n=\hat A_n(\mu_n)$ and
  $\hat q_{n\backslash i}=\hat A_n(\mu_{n\backslash i})$, where $\mu_n$ and
  $\mu_{n\backslash i}$ only differs in their $i$\textsuperscript{th} observation, which
  has been redrawn from $M$ in the case of $\mu_{n\backslash i}$. The algorithm $\hat A_n$
  is said to have \textsl{uniform stability} $\alpha_n$ if, for any $m\sim M$,
  \begin{equation*}
    |\ell(m,\hat q_n) - \ell(m,\hat q_{n\backslash i})| \leq \alpha_n. 
  \end{equation*}
\end{deff}

\begin{thm}
  If $\ell$ is $\sigma$-admissible and if, for any $x\in\bm X$, $\|x\|_2^2\leq\xMax^2$,
  then $\hat A_n$ has uniform stability with
  \begin{equation*}
    \alpha_n = \frac{\sigma^2 \xMax^2}{2\lambda n}.
  \end{equation*}
\end{thm}

\begin{proof}
  See Bousquet, Theorem 22. 
\end{proof}

\begin{rem}
  We conclude that $\hat A_n$ has uniform stability with
  \begin{equation*}
    \alpha_n = \frac{k^2\gamma^2(\bar r+R_f)^2\xMax^2}{2\lambda n}.
  \end{equation*}
\end{rem}

\begin{thm}
  \label{thm2}
  If $\hat A_n$ has uniform stability $\alpha_n$ and the loss function is such that for
  any $m\sim M$ and any $\hat q_n=\hat A_n(\mu_n)$, $|\ell(m,\hat q_n)|\leq B_n$, then for
  any $\delta\in(0,1)$, the following bound holds with probability at least $1-\delta$
  over the random sample draw $\mu_n\sim M_n$:
  \begin{equation*}
    |R(\qHat_n) - \hat R(\qHat_n)| \leq 2\alpha_n + (4n\alpha_n +
    B_n)\sqrt{\frac{\log(2/\delta)}{2n}} = \Omega_n.
  \end{equation*}
\end{thm}

\begin{proof}
  The original proof can be found in Bousquet 2002, Theorem 12. See also Rudin 2015,
  Theorem 2. \comment{Check conditions! $|\ell|\leq B$}
\end{proof}

\begin{rem}
  The highest loss occurs when investment decision is at its highest and the return at its
  lowest. From Claim \ref{claim_p_bound}, allocation scalar is bounded by $\bar p$ and we
  obtain $B_n = c(\bar p, -\bar r)$.
\end{rem}

We can finally draw a PAC bound on the out of sample average returns:
\begin{equation}
  \E[u^{-1}(-\ell(M,q))] \geq u^{-1}(-\hat R(\hat q_n) - \Omega_n).
\end{equation}
See Claim \ref{out_of_sample_claim} for further details.
 
\subsection{True Optimal Bound}

We now seek a bound on the empirical returns when compared to the out of sample returns
applying the (unknown) optimal decision vector $\qStar$. 

To do so, we can decompose the performance distance: \comment{Maybe it's tigher using
  another decomposition?}
\begin{equation*}
  |R(q^\star) - \hat R(\hat q_\lambda)| \leq |R(q^\star) + R(\hat q_\lambda)| 
  + |R(\hat q_\lambda) - \hat R(\hat q_\lambda)|.
\end{equation*}
Using Claim \ref{claim1}, the first term is bounded by
$k\gamma((\bar r+R_f)\xMax\|q^\star - \hat q_\lambda\|_2 + R_f)$, while the second one is
nothing more than $\Omega_n$. Now, unless we know the distribution of $M$, we can't bound
$\|q^\star\|_2$, however we know from Claim \ref{claim_finite} that it's
finite. Therefore, if we let $B^\star$ such that
\begin{equation*}
  \|q^\star - \hat q_\lambda\|_2 \leq B^\star,
\end{equation*}
then
\begin{equation*}
  |R(q^\star) - \hat R(\hat q_\lambda)| \leq k\gamma((\bar r+R_f)\xMax B^\star + R_f) +
  \Omega_n = \Omega^\star.
\end{equation*}


\section{Saturation}
In order to deal with the possible infinite support of the problem's features, we need to
come up with some kind of censoring or saturation if we want to obtain meaningful
guarantees. For example, if we have heavy tailed features distribution from which no
extreme event was sampled in our training set, we want safeguards in case such an extreme
point appears in the out of sample set. Otherwise, the decision scalar $q^Tx$ would
itself take unrealistic values. 

In order to contain the possible infinite support of $X_i$, we introduce a concave
function $g$ which we apply to $X_i^2$. In the simplest case, if $\hat X_i^2$ is the
sampled training set, then we can set $g:x\mapsto \min(x,\max\hat X_i^2)$, so that $\tilde
X^2_i = g(X_i^2)$ is a saturated (or censored in statistics terminology) version of
$X_i^2$. 

Notice that $g$ needs not be so harsh, for example it could be smoothed for
$x>\max \hat X_i^2$ using an inverse exponential. This would let extreme features values
have some limited effect on the decision. Anyway, its concavity means that
\[
\E \tilde X^2_i = \E g(X_i^2) \leq g(\E X_i^2) = 1,
\]
provided that $g(1) = 1$, since we assumed that $\E X_i=0$ and $\Var X_i=1$. Therefore if
we let $\tilde Z$ be the random vector of saturated features, then
$\|\tilde Z\|^2 = \sum_{i=1}^p\tilde X^2_i$, and $\E\|\tilde Z\|^2\leq p$.

We are now in a position to derive a concentration inequality of $\|\tilde Z\|^2$ around
$p$. We have on one side
\[
  \pp\{\|\tilde Z\|^2 \geq \epsilon + \E\|\tilde Z\|^2\} \geq \pp\{\|\tilde Z\|^2
  \geq \epsilon + p\}.
\]
On the other side, if we let $\hat M^2 = \sum_{i=1}^p \max \hat X^2_i$ be the in-sample
maximum \textbf{[It's possible to analyze $\hat M^2$ using concentration inequalities of
  suprema of empirical processes!  Also, we must realize that $\hat M^2 =
  O(p)$. Investigate.]}, then, using Hoeffding's theorem,
\[
  \pp\{\|\tilde Z\|^2 \geq \epsilon + \E\|\tilde Z\|^2\} \leq
  \exp\left(-\frac{2\epsilon^2}{\hat M^2}\right),
\]
and therefore
\[
  \pp\{\|\tilde Z\|^2 \geq \epsilon + p\} \leq \exp\left(-\frac{2\epsilon^2}{{\hat M}^2}\right). 
\]

Equivalently, we have, with probability $1-\delta$, 
\[
  \|\tilde Z\|^2 \leq p + \hat M\sqrt{\frac{\log(1/\delta)}{2}},
\]
ie. 
\[
  \|\tilde Z\| \leq O(\sqrt{p}).
\]

\newpage
\input{appendix}


\end{document}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
