\documentclass[10pt]{article}

\include{preamble}

\title{Big Data Statistical Portfolio Optimization}
\author{Thierry \textsc{Bazier-Matte} \and Erick \textsc{Delage}}

\begin{document}
\maketitle


The goal of this document is twofold. First, given a risk averse utility function and a
sample of the market observations (returns and states), we want to prescribe an optimal
linear investment policy depending on the risk aversion of the investor. Second, we also
wish to return to the investor probabilist bounds on the certainty equivalent of the
prescribed investment policy.

\section{Introduction}
\label{sec:intro}

Bla bla bla, Markowtiz \cite{markowitz1952portfolio}, etc. For modern treatment see
\comment{Robust Portfolio Optimzation.}

Following \cite{rudin2015big}, we investigate properties of the generalized linear
statistical learning framework in a big data situation.

\comment{Merge these two paragraphs together.}

This document investigates the role statistical learning can play in a portfolio
management context, especially when a portfolio manager is in a big-data situation,
ie. when $p=O(n^\gamma)$, where $n$ is the size of the training sample and $p$ is the number of
available features of the market, and $\gamma=O(1)$. The out of sample performance (oos) is of
utmost importance for portfolio managers, and statistical guarantees offered by our
framework suggest how $p$ and $n$ can interact to achieve a desired reduction in the
portfolio out of sample performance.

We first present how we can expand on the statistical literature by obtaining computable
PAC bounds $O(p/\sqrt{n}\lambda)$ on the oos performance, and then how they can bound the
certainty equivalent (CE) of a risk-averse investor. We also offer techniques in order to
make a general problem compliant with our hypotheses. We then investigate the properties
of our investment algorithm on synthetic market distributions, in particular worst-case
scenarios. Finally, we apply it to a high dimensional situation, exemplified with the use
of document NLP in order to represent the market.

\subsection{Main contributions}

This paper, in line with attempts made by \cite{rudin2015big}, is, to our knowledge, the
first to consider $p$ as parameter in itself, rather than as a constant. Therefore, we
expend on the empirical risk minimization (ERM) literature, while using classical tools
like algorithmic stability and concentration inequalities to provide bounds on
generalization. 

To our knowledge, the characterization of this framework in order to optimize an utility
function is also novel, as previous attempts would consider squared loss.


\subsection{Previous and related works}

This paper finds itself in continuity with previous attempts of building algorithmic
portfolios without making assumption on the market distribution, a construction sometimes
referred to as a `universal portfolio' \cite{cover1991universal}.

\section{Theoretical Framework}

\subsection{Assumptions and definitions}


In the following, $\bm A$ (capital boldface) are assumed to represent a real subset of any
dimension, $A$ (capital case) represents random variables (or distributions) and $a$
(lower case) represents deterministic variables or realizations. $\real$ represents the
real set.

Let $M=(X,R)$ be the unknown market distribution with support
$\bm M = \bm X\times \bm R \subseteq\real^{p+1}$, with $(x,r) = m\sim M$ a market
observation, consisting in one part state $x\in\real^p$ and another part outcome
$r\in\real$. Typically $x=(x_1,\dots,x_p)\sim X$ is a vector of observations from various
variable of interests, such as financial or economical news, etc. Scalar $r\sim R$ in this
article shall represent the return from a financial asset of interest. 

% Finally, let
% $M_n = \{M,\dots,M\}$ be a random set of $n$ (unrealized) observations (with support
% $\bm M^n$). Therefore $\mu_n \sim M_n$ represents an iid sample of $n$ market
% observations.

We shall study linear investment decisions $q\in\bm Q\subseteq\real^p$ such that
$p=q^Tx\in\bm I$ part of the portfolio is allocated to the risky asset with return $r$,
and $1-p$ part of the portfolio is allocated to a riskless asset. We will, for greater
simplicity, suppose that the riskless rate is $0$, so that the total return of the
portfolio is $rp$. 

% \begin{assumption}
%   Every feature $X_i$ and $X_j$ is pairwise independant. 
% \end{assumption}

% \begin{assumption}
%   Each feature has been standardized, ie. $\E X_i = 0$ and $\Var X_i = 1$. In particular,
%   this implies that $\E X_i^2 = 1$.
% \end{assumption}

\begin{assumption}
  The random return has a finite support, ie.
  $R\subsetsim \bm R \subseteq [r_{\min{}},r_{\max{}}]$. Additionally, $|R|\leq \bar r$.
\end{assumption}

\begin{assumption}
  The portfolio manager is endowed with an utility function $\bar u:\bm R\to \bm U$ with
  these properties:
  \begin{itemize}[noitemsep,topsep=0pt]
  \item $\bar u$ can be reexpressed as $\bar u(r) = ku(r) + l$, $k>0$, with $u(0) = 0$ and
    $\lim_{r\to0^+}u'(r) = 1$.
  \item $u(r) = o(r)$, ie. the investor is risk-averse;
  \item $|u(r_1) - u(r_2)| \leq \gamma|r_1-r_2|$, ie. $u$ is $\gamma$-Lipschitz;
  \item $u$ is monotonically increasing;
  \item With $u(r) = u_-(r)\bm1_{\{r<0\}}+u_+(r)\bm 1_{\{r\geq0\}}$, then $u_+(r) =
    o(u_-(r))$. In other words, $u_-$ decreases faster than $u_+$ increases. 
  \end{itemize}
\end{assumption}

\begin{deff}
  Let $\ell:\bm M\times \bm Q\to\bm U$ be a loss function defined by
  \[
    \ell(m,q) = \ell(x,r,q) = -u(rq^Tx)
  \]
  where $\rf$ is the risk free return rate. We also define the cost function
  $c:\bm I\times\bm R\to\bm U$ as
  \[
    c(p,r) = -u(rp),
  \]
  so that $\ell(x,r,q) = c(q^Tx,r)$. 
\end{deff}

\begin{deff}
  The in-sample risk $\hat R: \bm M^n\times \bm Q \to \bm U$ associated with decision $q$
  and market sample $\mu_n$ is given by
  \[
    \hat R_{\mu_n}(q) = n^{-1} \sum_{i=1}^n \ell(m_i,q).
  \]
\end{deff}

\begin{deff}
  The empirical decision algorithm $\hat A_n:\bm M^n \to \bm Q$ associated with
  market sample $\mu_n$ is the optimal value of the problem
  \[
    \text{minimize}\quad\hat R_{\mu_n}(q) + \lambda\|q\|^2.
  \]
\end{deff}

From now on, as a notation shortcut, let $\hat q_n := \hat A_n(\mu_n)$ the in-sample
decision associated with random market sample $\mu_n$ and $\hat R:=\hat R_{\mu_n}$ the
in-sample risk function.

\begin{deff}
  The in-sample certainty equivalent $\hat\CE:\bm M^n\times\bm Q\to\bm R$ associated with
  decision $q$ and market sample $\mu_n$ is given by
  \[
    \hat\CE(q) = ku^{-1}(-\hat R(q)) + l.
  \]
\end{deff}

% \comment{Remove unnecessary definitions.}

\begin{deff}
  The true risk $R:\bm Q\to\bm U$ associated with decision $q$ is given by
  \[
    R(q) = \E\ell(M,q).
  \]
\end{deff}

% \begin{deff}
%   The true regularized risk $R_\lambda:\bm Q\to\bm U$ associated with decision $q$ is
%   given by
%   \[
%     R_\lambda(q) = \E\ell(M,q) + \lambda\|q\|^2.
%   \]
% \end{deff}

% \begin{deff}
%   The optimal decision $q^\star$ is the optimal value of the problem
%   \[
%     \text{minimize}\quad R(q).
%   \]
% \end{deff}

% \begin{deff}
%   The optimal regularized decision $q^\star_\lambda$ is the optimal value of the
%   regularized problem
%   \[
%         \text{minimize}\quad R_\lambda(q).
%   \]
% \end{deff}

\begin{deff}
  The true certainty equivalent $\CE$ associated with decision $q$ is given by
  \[
    \CE(q) = ku^{-1}(-R(q)) + l.
  \]
\end{deff}

\subsection{Performance Bounds}

We are concerned about how the in sample performance can deviate from the expected out sample
performance, that is we want to identify $f_1$ such that
\[
  \CE(\hat q) \geq \hat\CE(\hat q) - f_1(n,p,\lambda)
\]
with high probability. We are also interested in the suboptimality of the problem, namely
the function $f_2$ such that
\[
  \CE(q^\star) \geq \CE(\hat q) - f_2(n,p,\lambda),
\]
also with high probability. 

The following theorem is adapted from \cite{bousquet2002stability}, and is the starting point of our
analysis. 

\begin{thm}
  \label{thm1}
  The in-sample and out-sample performance of the algorithm given by $\hat q$ is bounded
  by the following expression with probability $1-\delta$:
  \begin{align*}
    R(\hat q) &\leq \hat R(\hat q) + \frac{(\gamma\bar r\xMax)^2}{2\lambda n} +
    \left(\frac{(\gamma\bar r\xMax)^2}{\lambda} + \frac{\gamma(\gamma+1)\xMax^2\,r_{\max}\bar
    r}{2\lambda}\right)\sqrt{\frac{\log 1/\delta}{2n}}\\
              &:= \hat R(\hat q) + \Omega.
  \end{align*}
\end{thm}

\begin{proof}
  \comment{See claim ????? for further details.}
\end{proof}

\begin{thm}
  \label{thm2}
  The following inequality holds with probability $1-\delta$:
  \[
    \CE(\hat q) \geq \hat\CE(\hat q) + ku^{-1}(\Omega).
  \]
\end{thm}

\begin{proof}
  The following steps follow directly from the monotonicity, convexity, and
  superadditivity of $u^{-1}$ :
  \begin{align*}
    & R(\hat q) \leq \hat R(\hat q) + \Omega\\
    \iff & -R(\hat q) \geq -\hat R(\hat q) - \Omega\\
    \iff & u^{-1}(-R(\hat q)) \geq u^{-1}(-\hat R(\hat q) - \Omega)\\
    \iff & u^{-1}(-R(\hat q)) \geq u^{-1}(-\hat R(\hat q)) + u^{-1}(-\Omega)\\
    \iff & ku^{-1}(-R(\hat q))+l \geq ku^{-1}(-\hat R(\hat q))+l + ku^{-1}(-\Omega)\\
    \iff & \CE(\hat q) \geq \hat\CE(\hat q) + ku^{-1}(-\Omega).\qedhere
  \end{align*}
\end{proof}

\begin{thm}\
  \label{thm4}
  Likewise, the following inequality holds:
  \[
    \E_{\mu_n}[\CE(\hat q)] \geq 
  \]
\end{thm}

Since $\Omega>0$, it follows that $u^{-1}(-\Omega) > -\Omega$, therefore we have the
following relation:
\[
  \CE(\hat q) \geq \hat\CE(\hat q) - O\left(\frac{\xMax^2}{\sqrt{n}\lambda}\right).
\]


\subsection{Big Data Situation}

The literature revolving around Theorem \ref{thm1} and its applications ([Shai-Shalev,
Rudin]) generally leaves the $\xMax$ as an afterthought, but in real big-data contexts, if
$n$ is insufficiently large compared to $p$, than out-of-sample convergence might not be
certain. Actually, with $n=o(p^2)$, divergence is almost certain. 

Let's assume that $\E X_i = 0$ for all features, and let $Z^2 = \sum_{i=1}^p X_i^2$. In a
general setting, if $\E X_i^2 \leq M$, then $\E Z^2 \leq Mp$, and Markov's inequality
applies:
\[
  \pp\{Z^2 \geq t\} \leq \frac{\E Z^2}{t} \leq \frac{Mp}{t}.
\]
Equivalently, with probability $1-\delta$, 
\[
  Z^2 \leq \delta^{-1}Mp = O(p).
\]

If we further assume pairwise independance of features and that each feature is supported
by a closed interval, wether because the support of the feature is known to be bounded or
because it's been saturated in pre-processing, then each feature can be rescaled by $a_i$
so that so that $a_iX_i = \tilde X_i \subsetsim[-1,1]$, or $\tilde X_i^2
\subsetsim[0,1]$. Then, using Hoeffding's theorem,
\[
  \pp\{\tilde Z^2 \geq \tilde Mp + t\} \leq \exp\left(-\frac{2t^2}{p}\right),
\]
equivalently with probability $1-\delta$, 
\[
  \tilde Z^2 \leq \tilde Mp + \sqrt{\frac{p\log(1/\delta)}{2}} = O(p)
\]
Of course, it is easy to see that such a transformation is reversible. 

The point is that in general cases, we expect to have $\xMax^2 =O(p)$, so that the
convergence of our algorithm will be given by 
\[
  \CE(\hat q) \geq \hat\CE(\hat q) - O\left(\frac{p}{\sqrt{n}\lambda}\right).
\]


\include{appendix}

\printbibliography

\end{document}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:






