\documentclass[11pt,fleqn]{article}

\newcommand{\ts}{\textsuperscript}
\newcommand{\figref}[1]{Fig.~\ref{#1}}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{geometry}
\usepackage[parfill]{parskip}
\usepackage{bm}

\geometry{letterpaper}

\title{COMP 652 \\ End of Term Project}
\author{Thierry \textsc{Bazier-Matte}}
\date{April 2015}

\begin{document}
\maketitle

\section{Introduction}

The efficient market hypothesis states that there's no way to beat the market. At best, a
portfolio manager can try to reduce the variance on his returns by picking a large number
of stocks, following Markowitz theory. Hence the popular decision to invest in large
index, such as the S\&P500 or the Dow Jones, which provide a long-term assurance of
growing value, without the risk associated with speculation on a single asset.

However, given the current state of technology, where, with terminals like Bloomberg's, it
is trivial to obtain a large historical dataset on a variety of features, of a financial
nature or not, we can reevaluate if it is indeed impossible to beat the market. Such a
dataset could provide precious statistical information and it could be possible to
determine in which proportion does each feature has an impact on the observed results of
the market. 

This project will therefore try to address this interesting problem. We consider the
utility of an investor, that is, how risk-seeking or risk-adverse he is, in order to build
a portfolio reflecting his needs. As will be shown later, it is indeed possible to beat
the average market, especially if the utility is strongly risk-seeking. For more
conservative utilities, the model often reverts back to a much safer portofolio. 

The features used by this model will mostly be of a technical nature, ie. pure historical
financial data. It is however trivial to add any set of features to the model.

\section{Formal Problem}

We consider a machine $m$ that given a historical dataset of features $\{x_{st}\}$ will
return a decision vector $q$ from which we can make investment decision based on new
upcoming feature vectors. 

The investment decision is linear with respect to $q$, ie. $x_{st}^Tq$ is the allocation
of the portfolio to stock $s$. Because we also consider the risk-free asset, ie. a bank
loan, then the return on this decision at time $t+1$ will be
\begin{equation*}
  p_{st} = r_{s,t+1}\,x_{st}^Tq + R_f(1-x_{st}^Tq)
\end{equation*}
where $R_f$ is, for simplification purposes, a constant daily return rate. 

The decision vector $q$ to use will be based on the utility function of an investor. We
suppose this utility function to be of a concave two-pieces linear shape, mathematically
described as 
\begin{equation*}
  U(r) = p-r_c + \min(0,(\beta-1)(p-r_c))
\end{equation*}
where $0<\beta<1$ represents the lower rate at which the utility increase when exposed to
a return higher than $r_c$ (see \figref{fig:utility}), the critical return. Typically,
$r_c$ could be set to $R_f$ to reflect the fact that we would prefer our portfolio to be
at least as profitable as the risk-free rate, but it could be also set to $r_c=0$.

\begin{figure}
  \centering
  \includegraphics[width=0.7\textwidth]{Utility}
  \caption{Utility function, with $\beta=1/2$ and $r_c=5\%$}
  \label{fig:utility}
\end{figure}

We can then define $q$ to be the optimal vector in the sense that
\begin{equation*}
  q^\star = \frac{1}{N} \max_q \sum_{s,t} U(p_{st}),
\end{equation*}
ie. $q^\star$ is the decision vector maximizing the average utility over all $M$ training
instances $x_{st}$. $M$ would therefore be the number of data points (days in this case)
times the number of features.

This is an unbounded convex optimization problem, and so we must ensure to add a
constraint on the norm of $q$ or to add a $L_2$ regularization term to the objective, so
that a finite solution exists.



\section{Experimental Results}

Partial results were first conducted using a test set with historical data of seven firms:
MSFT, AAPL, GOOGL, BA, KO, MCD and CAT, all of them part of the Dow Jones.
\end{document}
