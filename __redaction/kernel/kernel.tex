\section{Introduction aux fonctions de décisions non linéaires}

Ce chapitre se veut une brève introduction aux propriétés des espaces de décision obtenus
par noyaux reproduisants. En premier lieu, une discussion sur la forme duale du problème
linéaire ainsi que les propriétés des espaces à noyau permettront d'obtenir une meilleure
intuition (Section \ref{k:def}). Par la suite, la Section \ref{k:alg} présentera quels
algorithmes permettant de trouver une politique d'investissement optimal à partir d'un
ensemble d'entraînement $\S_n = \{x_i,r_i\}_{i=1}^n \sim M^n$ échantilloné à partir de la
distribution de marché et d'une fonction d'utilité concave. Quelques exemples de noyaux
courants seront présentés, suivis des dérivations des deux formes d'optimisation.



\subsection{Propriétés des espaces de décision à noyau reproduisant}
\label{k:def}

\paragraph{Formulations primales et duales}

Tel que discuté en introduction, le cas le plus simple pour un espace de décision $\Q$ est
celui où $\Q = \X^*$, c'est-à-dire le dual de l'espace vectoriel $\X$\footnote{Le
  \textit{dual} $\bm V^*$ d'un espace vectoriel $\bm V$ correspond à l'ensemble des formes
  linéaires sur $\bm V$. Dans le cas fini où $\bm V = \Re^m$, alors un élément
  $w^* \in \bm V^*$ est souvent représenté par un vecteur ligne $w^T$ à $m$ éléments, tel
  que $w^*(v) = w^Tv.$}. La \textit{décision} prise suite à l'observation d'un vecteur
d'information $x\in\X$ est simplement $q(x) = q^Tx$. Le problème à résoudre est ainsi
\begin{equation}
  \label{k:primlin}
  \maximizeEquation[q\in\Re^p]{n^{-1}\sumi u(r_i\,q^Tx_i) - \lambda\|q\|^2,}
\end{equation}
duquel on tire un $\qh$ optimal. Cette formulation \textit{primale} est intuitivement
claire: on cherche à maximiser l'utilité moyenne suivant une politique unique $q$
appliquée à chaque observation $x_i$, tout en cherchant à éviter de favoriser
excessivement une des dimensions d'information par rapport aux autres. Or, selon le
théorème de la représentation qui sera présenté un peu plus loin (p.~\pageref{k:thmrep}),
la politique optimale $\qh$ peut également s'exprimer comme une combinaison linéaire des
observations $x_i$. Ainsi, en notant $\Xi \in \Re^{n \times p}$ la matrice des $n$ observations de
$x$, il existe $\hat\alpha \in \Re^n$ tel que
\begin{equation}
  \label{k:equiv}
  \qh = \Xi^T\hat\alpha.
\end{equation}
Cette propriété fondamentale permet donc de chercher une combinaison linéaire optimale
$\hat\alpha \in \Re^n$ à partir de laquelle la politique optimale peut être déduite. En substituant
\eqref{k:equiv} dans \eqref{k:primlin}, on obtient la \textit{représentation duale} du
problème:
\begin{equation}
  \maximizeEquation[\alpha\in\Re^n]{n^{-1}\sumi u(r_i\,\alpha^T\Xi x_i) - \lambda \alpha^T\Xi\Xi^T\alpha.}
\end{equation}
% Le problème est alors représenté en $n$ dimensions. Les $p$ variables de marché de chaque
% observation sont ainsi projetées sur une unique dimension; elles perdent alors toute
% distinction entre elles. Le rôle de $\alpha$ est alors de favoriser les dimensions avec
% lesquelles le vecteur d'observation $r$ a une covariance élevée.

% Intuitivement, et dans un monde risque neutre, le rôle de
% $\alpha$ est alors de déterminer comment se comporte la covariance 
Si, à des fins de simplification d'interprétation, l'investisseur est neutre au risque, et
en notant $K \coloneq \Xi\Xi^T \in \Re^{n \times n}$, \ie, $K_{ij} = x_i^Tx_j$, alors le problème sous sa
forme duale s'exprime comme
\begin{equation}
  \label{k:dualrn}
  \maximizeEquation[\alpha \in \Re^n]{n^{-1}\alpha^TKr - \lambda\alpha^TK\alpha.}
\end{equation}
Intuitivement, la matrice $K$, étant semi-définie positive, représente une
\textit{covariance de similarité} entre chacune des observations $x_i$, où la variance de
chaque observation est donnée par sa norme $\|x_i\|^2$ et la corrélation entre deux
observations par le cosinus de l'angle: $\rho_{ij} = x_i^Tx_j/\|x_i\|\|x_j\|$. L'expression
$n^{-1}Kr \in \Re^n$ indique quelles dimensions permettent d'obtenir le meilleur rendement en
considérant l'influence pondérée de toutes les observations:
\begin{equation}
  [Kr]_j = n^{-1}\sumi r_i\rho_{ij}\|x_i\|\|x_j\|.
\end{equation}
Le rôle de $\alpha$ est alors de choisir les dimensions les plus favorables; enfin le terme de
régularisation $\lambda\alpha^TK\alpha$ a pour effet non seulement de choisir une solution finie (puisque
quadratique), mais aussi de standardiser l'effet de chaque dimension afin de limiter par
exemple l'influence d'observations dotées d'une norme plus élevée que les autres.

On note finalement que la solution analytique du problème risque neutre devient
\begin{equation}
  K\alpha = \frac{1}{2n\lambda}Kr.
\end{equation}
entraînant sans surprise $\hat\alpha = (2n\lambda)^{-1}r$ si $K$ est de plein rang. Si par contre
$K$ n'est pas de plein rang, c'est-à-dire s'il existe une observation de norme nulle
($\|x_i\|=0$) ou colinéaire par rapport à une autre ($x_i = kx_j$ entraîne
$\rho_{ij} = 1$), $\hat\alpha$ n'est pas défini puisqu'il existe alors une infinité de
solutions. Il est à noter que le théorème de la représentation n'est pas forcément
\textit{nécessaire}, il est simplement suffisant.

Nous verrons cependant une autre forme duale au problème dont la solution $\hat\alpha$ est en
bijection avec $\qh$. 


\paragraph{Décisions non-linéaires}

Si cette classe des décisions linéaires a l'avantage d'être simple, elle est en revanche
fort peu adaptée à des situations pourtant peu complexes. Géométriquement, elle ne fait
que séparer l'espace $\X$ en deux: un côté entraînera des décisions d'investissement
positifs, l'autre des décisions négatives. \todo{Problème XOR irrésoluble}.

La méthode des noyaux permet de circonvenir ce problème en remplaçant la notion de
similarité entre deux points par une fonction de noyau semi-défini positif $\kappa$.

% Or, le problème
% \begin{equation}
%   \maximizeEquation[q\in\Re^p]{n^{-1}\sumi u(r_i\,q^Tx_i) - \lambda\|q\|^2}
% \end{equation}
% peut également être décrit comme (voir Section \ref{k:dem})
% \begin{equation}
%   \maximizeEquation[\alpha \in \Re^n]{-\sumi \ell^*(\alpha_i/r_i) - \frac{1}{4n\lambda}\alpha^TK\alpha.}
% \end{equation}
% où $\ell^*$ est le conjugué convexe de $-u$ et $K = \Xi^T\Xi \in \Re^{n\times n}$ est la matrice des
% produits scalaires des $n$ observations $x_i$. De plus, on passe de la représentation $\alpha$
% à $q$ par l'identité
% \begin{equation}
%   q = -\frac{1}{2n\lambda}\sumi \alpha_ix_i,
% \end{equation}
% de sorte que la décision sur une observation $x$ devient
% \begin{equation}
%   q(x) = -\frac{1}{2n\lambda}\sumi \alpha_ix_i^Tx.
% \end{equation}
% On a alors inversé le problème: les décisions d'investissement se prennent ici comme une
% somme \textit{pondérée} par $\alpha$ de l'influence des $x_i$ sur la nouvelle
% observation. Prenons par exemple le cas d'une utilité risque neutre. Alors $\ell^* = \infty$  sauf
% si $\alpha_i/r_i=-1$, donc nécessairement $\alpha = -r$ et alors
% \begin{equation}
%   q(x) = \frac{1}{2n\lambda}\sumi r_i x_i^Tx.
% \end{equation}
% Intuitivement, si la valeur absolue du rendement $r_k$ est élevé, on veut favoriser les
% observations semblables à $x_k$. Cette notion de similarité est ici définie par le produit
% scalaire $x_i^Tx_k = \|x_i\|\|x_k\|\cos\theta$; donc on cherchera à favoriser les $x$ de même
% direction que $x_k$ et d'amplitude au moins aussi élevée.

% Par ailleurs, le nouveau terme de régularisation $\alpha^TK\alpha$ peut s'interpréter comme la norme
% de $\alpha$ dans la base formée des observations $x_i$. Dans le cas le plus simple où $K$ est
% diagonale, on souhaite alors rétablir sur une même échelle toutes les mesures de
% similarité $\|x_i\|^2$ pour éviter de favoriser les points avec une norme trop
% élevés. Plus généralement, les vecteurs propres de $K$ indiquent quelles observations ont
% des co-similarités importantes, de manière à réduire leur impact sur la décision optimale
% $\alpha$.


\begin{deff}
  Un \textit{noyau semi-défini positif}, ou simplement un \textit{noyau}
  $\kappa:\X\times\X\to\Re$ est tel que pour tout ensemble $\{x_1,\ldots,x_n\}\in\X^n$, la matrice
  $K_{ij} = \kappa(x_i,x_j)$ est semi-définie positive.
\end{deff}

\begin{prop}
  Tout noyau semi-défini positif $\kappa$ induit un espace de décision $\Q$\footnote{Pour être
    tout à fait exact, $\Q$ est alors un espace de Hilbert à noyau reproduisant.} doté
  d'un produit scalaire $\inp{\cdot,\cdot}:\Q\times\Q\to\Re$ ainsi que d'une application
  $\phi:\X\to\Q$ donnée par $\phi(x) = \kappa(x,\cdot) = \kappa(\cdot,x)$. De plus, $\Q$ dispose de la propriété
  reproductive par laquelle pour tout $q \in \Q$, $q(x) = \inp{q,\phi(x)}$. En particulier on
  en conclut que $\kappa(x_1,x_2) = \inp{\phi(x_1),\phi(x_2)}$. Finalement, l'inégalité de
  Cauchy-Swartz s'applique à $\Q$: pour tout $q_1,q_2\in\Q$,
  $\inp{q_1,q_2}^2 \leq \nq{q_1}\nq{q_2}$, où la norme de $q$ est définie par
  $\nq{q}^2 = \inp{q,q}$. En particulier, on note que $q(x)^2 \leq \nq{q}\kappa(x,x)$.
\end{prop}

Ainsi, doté d'un noyau $\kappa$, on obtient un espace de décision $\Q$ tel que le problème
primal s'exprime par
\begin{equation}
  \maximizeEquation[q \in \Q]{n^{-1}\sumi u(r_i\,q(x_i)) - \lambda\nq{q}^2.}
\end{equation}
Il convient de noter que chaque type de noyau entraîne une classe de décision bien
particulière. Ainsi, selon la géométrie de la densité de la distribution $M$, certains
noyaux seront plus adaptés que d'autre. D'une certaine façon, il s'agit là d'une faiblesse
du modèle car celui-ci est incapable de \textit{déterminer} le bon noyau à employer et
cette tâche revient alors au gestionnaire de portefeuille.

\paragraph{Exemples}

Outre le \textit{noyau linéaire}, défini par $\kappa(x_1,x_2) = x_1^Tx_2$, les \textit{noyaux
  polynômiaux d'ordre $k$} donnés par $\kappa(x_1,x_2) = (x_1^Tx_2 +c)^k$ sont également
courants. Ces types de noyaux ont cependant l'inconvénient de conserver une notion
d'amplitude absolue; on peut à l'inverse définir des noyaux invariants au déplacement et à
la rotation, \ie\ tels que $\kappa(x_1,x_2) = \kappa(\|x_1-x_2\|)$. La notion de similarité ne
dépend alors plus que de la distance entre deux points. Ainsi, le noyau gaussien
$\kappa_\sigma$ sera défini par:
\begin{equation}
  \kappa_\sigma(x_1,x_2) = \exp\left(-\frac{\|x_1-x_2\|^2}{2\sigma^2}\right),
\end{equation}
où $\sigma$ représente la sensibilité du noyau; des valeurs élevées de $\sigma$ le rendront
rapidement insensible à des données pourtant rapprochées dans l'espace $\X$ alors qu'une
valeur $\sigma$ faible leur accordera une similarité beaucoup plus grande.

Enfin, ces noyaux peuvent se recombiner afin d'en former de nouveaux. Voir Bishop et
Mohri.


\subsection{Algorithmes de décision non-linéaires}
\label{k:alg}

Magré que le problème primal soit bien posé, l'espace $\Q$ est a priori inconnu et peut de
surcroit être de dimension infinie. Il est donc nécessaire de déterminer une méthode
algorithmique capable de déterminer $\qh$. Si la matrice de similarité $K$ est définie
positive, alors on peut utiliser le théorème de la représentation pour résoudre le
problème suivant:
\begin{equation}
  \maximizeEquation[\alpha \in \Re^n]{\sumi u(r_i\,\alpha^T\psi(x_i)) - \alpha^TK\alpha.}
\end{equation}
où $\psi:\X\to\Re^n$ est un opérateur linéaire tel que $\psi(x_i)_j = \kappa(x_i,x_j)$; c'est en fait la
contrepartie de l'application de $\Xi$ sur $x_i$ dans le cas linéaire. Par ailleurs la
décision optimale s'exprime comme $\qh = \hat\alpha^T\psi$, c'est-à-dire comme une combinaison
linéaire de fonctions non-linéaires. Enfin, si $K$ n'est pas définie positive, il suffit
alors de ne considérer que les points sans co-linéarité ou avec norme non nulle.

Il existe aussi une autre façon de résoudre le problème primal qui consiste à dualiser le
problème primal dans le cas linéaire pour voir émerger la matrice de similarité $K$, ce
qui permet alors de considérer n'importe quel noyau. Par ailleurs, cette méthode est
valide que $K$ soit de plein rang ou non. Ainsi, le problème primal peut se résoudre
suivant le problème
\begin{equation}
  \maximizeEquation[\alpha \in \Re^n]{-\sumi \ell^*(\alpha_i/r_i) - \frac{1}{4n\lambda}\alpha^TK\alpha.}
\end{equation}
La fonction $\ell^*:\Re\to\Re$ est le \textit{conjugué convexe} de la fonction de perte
$\ell = -u$ (voir \eqref{k:eqconvconj}, p.~\pageref{k:eqconvconj}). La décision est donnée
par
\begin{equation}
  q(x) = -\frac{1}{2n\lambda}\alpha^T\psi(x).
\end{equation}

Par exemple, dans le cas d'une utilité risque neutre, $\ell^* = \infty$ sauf si
$\alpha_i/r_i=-1$, donc nécessairement $\alpha = -r$ et alors
\begin{equation}
  q(x) = \frac{1}{2n\lambda} r^T\psi(x).
\end{equation}

\subsection{Démonstrations}

\label{k:dem}

\paragraph{Approche duale}

On cherche à résoudre le problème suivant, avec $q \in \Re^p$ comme variable d'optimisation:
\begin{equation}
  \label{primal}
  \minimizeEquation{\sumi \ell(r_i\,q^Tx_i) + n\lambda\|q\|^2,}
\end{equation}
où $\ell=-u$. De façon équivalente, en introduisant un nouveau vecteur $\xi \in \Re^n$, on a
\begin{equation}
  \minimizeEquationSt{\label{primal2}\sumi \ell(\xi_i) + n\lambda\|q\|^2}[\xi_i = r_i\,q^Tx_i.] 
\end{equation}
Soit $\alpha\in\real^n$. Le lagrangien de \eqref{primal2} peut s'exprimer comme
\begin{equation}
  \lag(q,\xi,\alpha) = \sumi \ell(\xi_i) + n\lambda\|q\|^2 + \sumi \alpha_i(r_iq^Tx_i - \xi_i).
\end{equation}
Puique l'objectif de \eqref{primal2} est convexe et que ses contraintes sont affines en
$q$ et $\xi$, on peut appliquer le théorème de Slater qui spécifie que le saut de dualité
du problème est nul. En d'autres mots, résoudre \eqref{primal} revient à maximiser la
fonction dual de Lagrange $g$ sur $\alpha$:
\begin{equation}
  \maximizeEquation{g(\alpha) = \inf_{q,\xi} \lag(q,\xi,\alpha).}
\end{equation}
On note que
\begin{align}
  g(\alpha)
  &= \inf_{q,\xi} \left\{\sumi \ell(\xi_i) + n\lambda\|q\|^2 + \sumi \alpha_i(r_iq^Tx_i -
    \xi_i)\right\}\\
  &= \inf_\xi\left\{\sumi \ell(\xi_i) - \alpha^T\xi\right\} + \inf_q\left\{\sumi \alpha_ir_iq^Tx_i +
    n\lambda\|q\|^2\right\}\\
  & = -\sup_\xi\left\{a^T\xi - \sumi \ell(\xi_i)\right\} + \inf_q\left\{\sumi \alpha_ir_iq^Tx_i +
    n\lambda\|q\|^2\right\}\\
  & = -\sumi \ell^*(\alpha_i) + \inf_q\left\{\sumi \alpha_ir_iq^Tx_i +n\lambda\|q\|^2\right\}.\label{deriv1} 
\end{align}
Où $\ell^*$ est le conjugé convexe de la fonction de perte et est définie par 
\begin{equation}
  \label{k:eqconvconj}
  \ell(\alpha_i) = \sup_{\xi_i}\left\{\alpha_i\xi_i - \ell(\xi_i)\right\}.
\end{equation}
On note par ailleurs l'usage de l'identité
\begin{equation}
  \label{lemma1}
  f(\xi_1,\dots,\xi_n) = \sumi \ell(\xi_i) \Longrightarrow f^*(\xi_1,\dots,\xi_n) = \sumi \ell^*(\xi_i)
\end{equation}
À présent, considérons le second terme de  \eqref{deriv1}. Puisque l'expression est
dérivable, on peut résoudre analytiquement $q$.
\begin{equation}
  \nabla_q \left\{\sumi \alpha_ir_iq^Tx_i + n\lambda\|q\|^2\right\} = 0
\end{equation}
implique que
\begin{equation}
 q = -\frac{1}{2n\lambda}\sumi \alpha_ir_ix_i \label{qdef}
\end{equation}
à l'infimum.

En utilisant \eqref{qdef}, on peut éliminer $q$ de \eqref{deriv1} pour obtenir
\begin{align}
  g(\alpha) &= -\sumi \ell^*(\alpha_i) - \frac{1}{2n\lambda}\sumij \alpha_i\alpha_jr_ir_jx_i^Tx_j + \frac{1}{4n\lambda}
         \sumij \alpha_i\alpha_jr_ir_jx_i^Tx_j\\
       &= -\sumi \ell^*(\alpha_i) - \frac{1}{4n\lambda}(\alpha \circ r)^TK(\alpha \circ r). 
\end{align}
Ainsi, sous sa forme duale, le problème \eqref{primal} est équivalent à résoudre
\begin{equation}
  \label{dual}
  \minimizeEquation{\sumi \ell^*(\alpha_i) + \frac{1}{4n\lambda}(\alpha \circ r)^TK(\alpha \circ r).}
\end{equation}
On peut finalement définir $\tilde\alpha_i = \alpha_i/r_i$ pour obtenir le résultat annoncé plus haut.


\paragraph{Approche primale}


Soit $\kappa: \X \times \X \to \Re$ un noyau semi-défini positif, $\Q$ l'espace de décision induit par
$\kappa$ et $K \in \Re^{n \times n}$ la matrice de similarité. Le problème d'optimisation de
portefeuille régularisé s'exprime alors par
\begin{equation}
  \label{k:basic}
  \maximizeEquation[q \in \Q]{n^{-1}\sumi u(r_i\,q(x_i)) - \lambda\nq{q}^2.}
\end{equation}

Tel que mentionné, la dimension de $\Q$ est possiblement infinie, ce qui rend
numériquement impossible la recherche d'une solution $q^\star$. Toutefois, le théorème de la
représentation permet de rendre le problème résoluble. 

\begin{thm}[Théorème de la représentation]
  \label{k:thmrep}
  Toute solution $q^\star$ de \eqref{k:basic} repose dans le sous-espace vectoriel engendré
  par l'ensemble des $n$ fonctions $\{\phi_i\}$, où $\phi_i = \kappa(x_i,\cdot)$. Numériquement, il
  existe un vecteur $\alpha \in \Re^n$ tel que,
  \begin{equation}
    q^\star = \sumi \alpha_i \phi_i = \alpha^T\phi.
  \end{equation}
\end{thm}
\begin{proof}
  Voir \cite{mohri2012foundations}, Théorème 5.4 pour une démonstration tenant compte d'un
  objectif régularisé général. La démonstration est dûe à \cite{kimeldorf1971some}.
\end{proof}

Le théorème de la représentation permet donc de chercher une solution dans un espace à $n$
dimensions, plutôt que la dimension possiblement infinie de $\Q$. En effet, puisque
\begin{equation}
  q^\star = \sumi \alpha_i \phi_i,
\end{equation}
où $\alpha \in \Re^n$, on peut donc restreindre le domaine d'optimisation à $\Re^n$. L'objectif de
\eqref{k:basic} devient alors
\begin{equation}
  n^{-1}\sumi u(r_i \textstyle \sumj \alpha_j \phi_j(x_i)) - \lambda \langle q,q \rangle_{\Q}. 
\end{equation}
Le premier terme se réexprime comme
\begin{equation}
  n^{-1} \sumi u(r_i\,\alpha^T\phi(x_i)),
\end{equation}
alors qu'en employant les propriétés de linéarité du produit intérieur, on transforme le
second terme par
\begin{align}
  \inp{q,q}^2 &= \sumi \sumj \alpha_i \alpha_j \inp{\phi_i,\phi_j}\\
                 &= \sumi \sumj \alpha_i \alpha_j \kappa(x_i,x_j)\\
                 &= \alpha^T K \alpha.
\end{align}
De sorte que le problème général \eqref{k:basic} peut se reformuler par
\begin{equation}
  \maximizeEquation[\alpha \in \Re^n]{n^{-1}\sumi u(r_i \alpha^T \phi(x_i)) - \lambda\,\alpha^TK\alpha}.
\end{equation}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main_kernel"
%%% End:
