\documentclass[11pt]{article}

\newcommand{\ts}{\textsuperscript}
\newcommand{\figref}[1]{Fig.~\ref{#1}}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{graphicx}
\usepackage{geometry}
\usepackage{subcaption}
\usepackage{bm}
\usepackage{hyperref}
\usepackage[retainorgcmds]{IEEEtrantools}
\usepackage{mathtools}
\usepackage{color}
\usepackage{marginnote}
\usepackage[utf8]{inputenc}


\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator{\st}{s.t.}
\DeclareMathOperator{\epi}{epi}
\DeclareMathOperator{\diag}{diag}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}

\newcommand{\iso}{\simeq}
\newcommand{\dd}{\partial}
\newcommand{\real}{\bm R}


\newcommand{\hilight}[1]{\colorbox{yellow}{#1}}
\let\oldmarginnote\marginnote
\renewcommand{\marginnote}[1]{\oldmarginnote{\footnotesize\emph{#1}}[0cm]}

\theoremstyle{plain}
\newtheorem{prop}{Proposition}
\newtheorem{thm}{Theorem}

\theoremstyle{definition}
\newtheorem*{deff}{Definition}
\newtheorem*{rem}{Remark}


\geometry{letterpaper}
\IEEEeqnarraydefcolsep{0}{\leftmargini}

\title{The Big Data Newsvendor Problem in a Portfolio Optimization Context}
\author{Thierry \textsc{Bazier-Matte}}
\date{Summer 2015}

\begin{document}
\maketitle

\begin{abstract}
  Following \cite{rudin2015}, we provide a portfolio optimization method based on machine
  learning methods.
\end{abstract}


\section{Introduction}
\label{sec:intro}

\marginnote{Maybe considerations about the length of the period should be added? For
  example, it's not specified what's the period length of $R_f$.}  This document considers
a two-asset portfolio, of which one is the risk-free asset, yielding a constant return
rate $R_f$, and the other being a risky asset $s$, typically a stock, yielding a random
return rate $r_{st}$ for each period $t$. We suppose that each risky asset $s$ can be
decribed daily by an \emph{information vector} $x_{st}$ containing potentially useful
information, such as technical, fundamental or news-related information. Furthermore, we
assume that the allocation of each asset of the portfolio $p_{st}$ can be fully determined
using a \emph{decision vector} $q$. The allocation rule is the folowing: $q^Tx_{st}$ is
allocated to the risky asset and $1-q^Tx_{st}$ is allocated to the risk-free asset. Over
the period $t$, the portfolio $p_{st}$ consisting of asset $s$ will therefore yield a
return rate of:
\begin{equation}
  p_{st}(q) = r_{st}q^Tx_{st} + (1-q^Tx_{st})R_f.
\end{equation}

The question we now wish to ask is how the decision vector $q$ should be chosen. We assume
we have access to a training dataset $S_n$, comprising of $s$ different assets over
$t$\marginnote{What's the difference between having $n$ points with having $s\times t$
  points? For example, what if $s\gg t$ or the reverse?} periods, such that
$n = s\times t$. 



\section{Definitions and Bounds}

\subsection{Definitions Notation}

Most of the following notation and defintions follow directly from \cite{bousquet2002}.

Let $S_n$ be a set of $n$ vectors of $\real^p\times\real$ of the form:
\begin{equation}
  S_n = \{(x_1,r_1),\ldots,(x_n,r_n)\}.
\end{equation}
Each component of $S_n$ is a tuple $(x,r)$, where $x$ is the information vector and $r$ is
the observed return rate.

Using $S_n$, we wish to create a decision vector $q_{S_n}\in\real^p$ from which we can
make an investment decision when confronted with a random draw $d=(x,r)$.

\paragraph{Loss and Cost.}
We introduce the loss $\ell$ and the cost $c$ of using $q$ with a random draw $d=(x,r)$:
\begin{equation}
\ell(q,d) = c(q(x),r) = c(q^Tx,r)
\end{equation}

Supposing an utility $U$, there are two different cost functions we can use. The first
one, and perhaps the most obvious one is defined by
\begin{equation}
  c(p,r) = -U(pr + (1-p)R_f).
\end{equation}
If the utility is piecewise linear, then the cost is not bounded, and so an infinite
return would yield a negatively infinite cost. This means that risk-taking will be
encouraged since risky position, ie. $|p|>1$ can in fact yield a negative cost. On the
other hand, with an unbounded utility, the algorithm minimizing the cost over the sample
must have $\lambda > 0$, otherwise the problem might be unconstrained. 

We can also define a new cost function that is always non-negative:
\begin{equation}
  c(p,r) =
  \begin{cases}
    \lfloor U(r) - U(pr + (1-p)R_f)\rfloor & \text{if } r>R_f\\
    \lfloor U(R_f) - U(pr + (1-p)R_f)\rfloor &\text{if } r\leq R_f,
  \end{cases}
\end{equation}
where by $\lfloor \cdot \rfloor$ we mean $\max(.,0)$. In the case of exponential
utilty, this cost function is actually equivalent to the one previously defined, but is
quite different in the case of an unbounded utility function, for example the piece-wise
linear one. Such a cost does not encourage risky position, since the cost is at least
0. This means that if $r>0$, then there's no point having $p>1$ instead of $p=1$ since
both will yield a zero cost position. 

\paragraph{Utility.}
There are two ways we can model our utility, and both are concave shaped, to represent a
risk-averse approach. The first utility is the linear utility of the form
\begin{equation}
  U(r) = r + \min(0, \beta r),
\end{equation}
with $0<\beta<1$. The other utility is exponential:
\begin{equation}
  U(r) = -\exp(-\mu r),
\end{equation}
with $\mu > 0$.

\begin{figure}
  \centering
  \begin{subfigure}{.4\textwidth}
  \includegraphics[width=1.1\textwidth]{ExpULossAboveZero.pdf}
\end{subfigure}%
\begin{minipage}{.4\textwidth}
  \includegraphics[width=1.1\textwidth]{ExpULossBelowZero.pdf}
\end{minipage}
\end{figure}

\paragraph{Algorithm.}
We will be concerned with probabilistic confidence bounds on results produced using the
following algorithm, using dataset $S_n$.
\begin{equation}
  \label{algo}
  q^\star = \argmin_{q\in\real^p}\frac{1}{n} \sum_{i=1}^{n} c(q^Tx_i,r_i) + \lambda\|q\|^2_2.
\end{equation}

\paragraph{Assumptions.}
We will assume that information vectors have been pre-processed and lie in a $X^2_{\max}$
radius ball. We also assume that the return rates observed are comprised within $[-\bar r,
\bar r]$. This last assumption will be relaxed. 

\marginnote{Include reference for definitions and theorems}

\begin{deff}
  An algorithm $A$ has uniform stability $\beta$ with respect to the loss function $\ell$
  if, for all $S_n\in\bm D^n$ and $i\in\{1,\ldots,n\}$, the following holds:
  \begin{equation}
    \|\ell(A_{S_n},.) - \ell(A_{S^{\backslash i}_n},.)||_{\infty} \leq \beta_n,
  \end{equation}
  or, equivalently,
  \begin{equation}
    \sup_{d\in\bm D}|\ell(A_{S_n},d) - \ell(A_{S^{\backslash i}_n},d)| \leq \beta_n.
  \end{equation}
  Here, $S^{\backslash i}$ means the set $S$ with the $i$th data point removed.

  Furthermore, $A$ is stable when $\beta_n = O(1/n)$.
\end{deff}

\begin{deff}
  A loss function $\ell$ is $\sigma$-admissible if the associated cost function $c$ is
  convex with respect to its first argument and the following condition holds for any
  $p_1,p_2$ and $r$:
  \begin{equation}
    |c(p_1,r) - c(p_2,r)| \leq \sigma |p_1 - p_2|
  \end{equation}
\end{deff}

\begin{rem}
  Our loss function $\ell$ is $\sigma$-admissible with $\sigma=\bar r+R_f$ in the linear
  case and $\sigma=(\bar r+R_f)\exp(\mu\bar r)$ in the exponential case.
\end{rem}

\begin{proof}
  First, we remark that both forms of $U$ yield a convex function of $p$ with $r$ fixed. 

  Now we'll suppose that $c(p_1,r), c(p_2,r) > 0$. Then the expression
  $|c(p_1,r)-c(p_2,r)|$ reduces to
  \begin{equation}
    \label{eq:above1}
    |U(p_1r + (1-p_1)R_f) - U(p_2r + (1-p_2)R_f|.
  \end{equation}
  Now because $r\in[-\bar r,\bar r]$, $U$ is Lipschitz continuous on its domain, and so
  \eqref{eq:above1} is bounded by
  \begin{equation}
    \label{eq:above2}
    \alpha |p_1r + (1-p_1)R_f - (p_2r + (1-p_2)R_f)| = \alpha|p_1-p_2||r-R_f|
  \end{equation}
  where
  \begin{equation}
    \alpha = \sup_{r\in[-\bar r,\bar r]} |U'(r)|.
  \end{equation}

  In the linear case, the derivative is piecewise constant, and is set to 1 on for returns
  below $r_c$, so that $\alpha=1$. In the exponential case, $U'(r) = \exp\mu r$, and
  $\alpha = \exp \mu \bar r$.

  The bound \eqref{eq:above2} must hold for any $r$. The expression $|r-R_f|$ will reach
  its largest value at $r=-\bar r$, since $R_f$ is assumed to be non-negative.

  Finally we consider the case where, without loss of generality, $c(p_2,r)=0$. Then, if
  $c$ had not been defined using $\lfloor\cdot\rfloor$, then we would have
  \begin{align}
    |\floor*{c(p_1,r)} - \floor*{c(p_2,r)}| &\leq |c(p_1,r) - c(p_2,r)|\\
    &\leq \sigma|p_1-p_2|.\qedhere
  \end{align}
\end{proof}

\begin{thm}
  Let $F$ be a reproducing kernel Hilbert space with kernel $\kappa$ that
  $\forall x\in X$, $\kappa(x,x) \leq \kappa^2 <\infty$. If $\ell$ is $\sigma$-adimissible
  with respect to $F$, then the learning algorithm defined by
  \begin{equation}
    \label{eq:above3}
    A_S = \argmin_{g\in F}\frac{1}{n}\sum_{i=1}^n \ell(g,d_i) + \lambda\|g\|^2_k
  \end{equation}
  has uniform stability $\alpha_n$ with respect to $\ell$ with
  \begin{equation}
    \alpha_n \leq \frac{\sigma^2 \kappa^2}{2\lambda n}.
  \end{equation}
\end{thm}

\begin{rem}
  Our proposed algorithm has the form \eqref{eq:above3}, and so has algorithmic stability
  bounded by
  \begin{equation}
    \alpha_n \leq \frac{(\bar r+R_f)^2X^2_{\max}}{2\lambda n}
  \end{equation}
  with linear utility and
  \begin{equation}
    \alpha_n \leq \frac{\exp(2\mu\bar r)X^2_{\max}}{2\lambda n}
  \end{equation}
  in the case of exponential utility.
\end{rem}

\begin{deff}
  The \emph{true risk} with respect to algorithm $A$ and set $S_n$ is defined as
  \begin{equation}
    R_{\text{true}}(A,S_n) = E_d[\ell(A_{S_n},d)],
  \end{equation}
  which is, in plain words, the expected loss incured when applying the algorithm created
  from training set $S_n$ in the wild, ie. out of sample.
\end{deff}

\begin{deff}
  The \emph{empirical risk} with respect to algorithm $A$ and set $S_n$ is defined as
  \begin{equation}
    \hat R(A,S_n) = \frac{1}{n} \sum_{i=1}^n \ell(A_{S_n},d_i),
  \end{equation}
  which is, in plain words, the average cost incured by our model over all the training
  set.
\end{deff}

\begin{rem}
  The maximum loss we can suffer over a single data point happens when $r_i=-\bar r$ and
  $p=1$, ie.
  \begin{equation}
    c(1,-\bar r) = U(R_f) - U(\bar r).
  \end{equation}
  We shall call this quantity $\gamma$.
\end{rem}

\begin{thm}
  Let $A$ be an algorithm with uniform stability $\alpha_n$ with respect to a loss
  function $\ell$ such that $0\leq\ell(A_{S_n},d)\leq M$ for all $d=(x,r)\sim D$ and all sets
  $S_n$ of size $n$. Then for any $n\geq1$ and any $\delta\in(0,1)$, the following bound
  holds with probability at least $1-\delta$ over the random draw of the sample $S_n$:
  \begin{equation}
    |R_{\text{true}}(A,S_n) - \hat R(A,S_n)| \leq 2\alpha_n + (4n\alpha_n + M) \sqrt{\frac{\log(2/\delta)}{2n}}.
  \end{equation}
\end{thm}

\begin{rem}
  Our algorithm has a generalization bound of
  \begin{equation}
    |R_{\text{true}}(A,S_n) - \hat R(A,S_n)| \leq 2\alpha_n + (4n\alpha_n + \gamma) \sqrt{\frac{\log(2/\delta)}{2n}}.
  \end{equation}
\end{rem}


\section{Multi-asset Portfolio}

We now consider a multi-asset portfolio, made of $m$ risky assets and a risk-free
asset. Each of theses risky assets have information vector $x_{st}$, where
$s\in\{1,\ldots,m\}$ and $t\in\{1,\ldots,n\}$. Therefore, we suppose having access to a
sample dataset $S_n = \{X_1,\ldots,X_n\}$ where $X_i\in\real^{m\times p}$.

There are two ways to approach the multi-asset scenario. 


\subsection{First approach}

On one hand, we can define a single decision vector $q$ such that the return on a single
holdinq period would be defined by
\begin{equation}
  r^{T}Xq + (1 - 1^{T}Xq)R_f,
\end{equation}
where $r\in\real^{m}$ is the return vector of the $m$ stocks and $1^T$ is a contant vector
of ones in $\real^m$ whose role is simply to sum over the components of $Xq$, ie. sum over
the risky allocations of the portfolio. However, this method has the disadvantage that the
decision vector is applied for each stock in the same way, and so all their information
vectors are ultimately `averaged' over. Therefore, if some asset is more sensitive to an
information component than other assets, this knowledge might be lost if using this
method. 

Nevertheless, we can again define two different cost functions, which our optimal decision
vector would minimize when applied to our sample dataset $S_n$. Again, the cost can be
simply defined as
\begin{equation}
  c(p,r) = -U(r^{T}p + (1 - 1^{T}p)R_f).
\end{equation}
As discussed previously, this definition might have the disadvantage of providing an
unconstrained optimization problem when determining the optimal decision vector.

We are not limited to a single cost definition, and in fact, the multi-asset scenario
provides many legitimate cost definitions. Here the most `aggressive' one:
\begin{equation}
  c(p,r) =
  \begin{cases}
    \floor{U(\max r) - U(r^{T}p + (1-1^{T}p)R_f)} & \text{if } \max r>R_f\\
    \floor{U(R_f) - U(r^{T}p + (1-1^{T}p)R_f)} &\text{if } \max r\leq R_f.
  \end{cases}  
\end{equation}
This means that we expect (or conversely, that we suffer a lesser loss) when the total
return of our portfolio is near the best return achieved by our considered stocks. Instead
of $\max r$, we also could have chosen the average returns $\bar r$ during the period as
the target that we wish to achieve (provided that the average is superior to the risk-free
return). We could in fact chose any function mapping from a vector of returns $r$ to a
scalar as our global return objective.

In any case, the algorithm determining the decision vector $q$ would once be defined as
previously, ie. as \eqref{algo}.


\subsection{Second approach}

Under this second approach, instead of averaging over all information vector at the risk
of losing asset-specific information, we now use a decision matrix $Q$ of size $p\times
m$, whose $m$ columns are actually trained independently one to each other so that each
asset reacts differently from the rest. 

The allocation of each vector would then be $\diag(XQ)$, ie. the diagonal elements of the
$m\times{}m$ matrix $XQ$. The one-period return is therefore
\begin{equation}
  r^{T}\diag(XQ) + (1 - 1^{T}\diag(XQ))R_f.
\end{equation}

This method still has a disadvantage though, in that it won't consider the eventual
influence of information $x_j$ of asset $j$ to asset $j$, ie. each stock is trained
independantly one to each other.

\subsection{Third Approach}

Finally, we introduce a third approach with the objective of using all available data of
the market, available through $X\in\real^{m\times p}$. However, we must be clear about
what information $X$ carries with it; its information is only bounded to different
assets, and therefore does not include `global' information with it.

Following a simple idea introduced by \cite{wsj}, we can add an unknown linear
transformation $W$ to $X$ so that $q$ can benefit from the whole information matrix, and
not only from the average of its columns. The total return using a transformation $W$ and
decision vector $q$ would therefore be expressed as
\begin{equation}
  r^{T}XWq + (1 - 1^{T}XWq)R_f.
\end{equation}

\begin{thebibliography}{99}

\bibitem{rudin2015}
  Cynthia Rudin and Gah-Yi Vahn. \textit{The Big Data Newsvendor: Pratical Insights from
    Machine Learning}, Operations Research, 2015.

\bibitem{bousquet2002}
  Olivier Bousquet and Andr√© Elisseeff. \textit{Stability and Generalization}, Journal of
  Machine Learning Research, 2002.

\bibitem{rockafellar}
  Rockafellar, R.~T. \emph{Convex Analysis}, Princeton University Press, 1970.

\bibitem{wsj} Ming Fai Wong et al. \emph{Stock Market Prediction from WSJ: Text Mining via
    Sparse Matrix Factorization.} ICDM 2014. 

\end{thebibliography}
\end{document}
