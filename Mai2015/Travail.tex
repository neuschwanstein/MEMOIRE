\documentclass[11pt,fleqn]{article}

\newcommand{\ts}{\textsuperscript}
\newcommand{\figref}[1]{Fig.~\ref{#1}}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{graphicx}
\usepackage{geometry}
\usepackage[parfill]{parskip}
\usepackage{bm}
\usepackage{hyperref}
\usepackage[retainorgcmds]{IEEEtrantools}
\usepackage{color}
\usepackage{marginnote}
\usepackage[utf8]{inputenc}


\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator{\st}{s.t.}
\DeclareMathOperator{\epi}{epi}

\newcommand{\iso}{\simeq}
\newcommand{\dd}{\partial}
\newcommand{\real}{\bm R}


\newcommand{\hilight}[1]{\colorbox{yellow}{#1}}
\let\oldmarginnote\marginnote
\renewcommand{\marginnote}[1]{\oldmarginnote{\footnotesize\emph{#1}}[0cm]}

\theoremstyle{plain}
\newtheorem{prop}{Proposition}

\theoremstyle{definition}
\newtheorem*{deff}{Definition}


\geometry{letterpaper}
\IEEEeqnarraydefcolsep{0}{\leftmargini}

\title{The Big Data Newsvendor Problem in a Portfolio Optimization Context}
\author{Thierry \textsc{Bazier-Matte}}
\date{Summer 2015}

\begin{document}
\maketitle

\begin{abstract}
  Following \cite{rudin2015}, we provide a portfolio optimization method based on machine
  learning methods.
\end{abstract}

\section{Introduction}
\label{sec:intro}

\marginnote{Maybe considerations about the length of the period should be added? For
  example, it's not specified what's the period length of $R_f$.}  This document considers
a two-asset portfolio, of which one is the risk-free asset, yielding a constant return
rate $R_f$, and the other being a risky asset $s$ , typically a stock, yielding a random
return rate $r_{st}$ for each period $t$. We suppose that each risky asset $s$ can be
decribed daily by an \emph{information vector} $x_{st}$ containing potentially useful
information, such as technical, fundamental or news-related information. Furthermore, we
assume that the allocation of each asset of the portfolio $p_{st}$ can be fully determined
using a \emph{decision vector} $q$. The allocation rule is the folowing: $q^Tx_{st}$ is
allocated to the risky asset and $1-q^Tx_{st}$ is allocated to the risk-free asset. Over
the period $t$, the portfolio $p_{st}$ consisting of asset $s$ will therefore yield a
return rate of:
\begin{equation}
  p_{st}(q) = r_{st}q^Tx_{st} + (1-q^Tx_{st})R_f.
\end{equation}

We further suppose that the \emph{utility} derived from a return rate $p$ can be described
using a concave two-pieces linear function of the following form:
\begin{equation}
  U(p) = p-r_c + \min((\beta-1)(p-r_c),0),
\end{equation}
where $r_c$ is an arbitrary \emph{critical rate}. We impose the condition $0<\beta<1$, so
that the utility derived from rates inferior to the critical rate $r_c$ increases more
sharply than from rates above $r_c$. Typically, the critical rate could be 0, but it could
also be $R_f$. This is up to the investor.\marginnote{More on it?}

The question we now wish to ask is how the decision vector $q$ should be chosen. We assume
we have access to a training dataset $S_n$, comprising of $s$ different assets over
$t$\marginnote{What's the difference between having $n$ points with having $s\times t$
  points? For example, what if $n\gg t$ or the reverse?} periods, such that
$n = s\times t$. Given such a training set, we then define the \emph{optimal decision
  vector} $q^\star$ as the decision maximizing the average utility over the training set:
% TODO: Find a better way to input optimization equations
\begin{align}
  q^\star &= \argmax_q \hat U\\
          &= \argmax_q \frac{1}{n}\sum_{s,t} U(p_{st}(q)).
\end{align}
The above optimization problem is linear and can therefore be readily solved with any
modern computer.

However, we also wish to add a $L_2$ regularization term to the objective in order to
avoid overfitting. The new learning algorithm is then
\begin{align}
  q^\star &= \argmax_q \frac{1}{n} \sum_{s,t} U(p_{st}(q)) - \lambda \|q\|^2.
\end{align}
Now even though this new problem is no longer linear, it is still convex and can therefore be
efficiently solved.

We will refer to these two algorithms as respectively the non-regularized or linear
algorithm and the regularized algorithm.

\section{Bounds}
\label{sec:bounds}

\marginnote{Careful: distribution and space are not the same, but are treated equal.}
Let $\bm R$ be the distribution of the returns of all considered assets. We suppose in this
section that the distribution of absolute returns is bounded by $\bar r$. 

Let also $\bm X\iso\bm{R}^p$ be the \emph{restricted information space} and $\bm
D= \bm R\times\bm X$ be the \emph{information space}. $\bm D^n$ is therefore the
\emph{observation space}, containing $n$ observations.

The utility function being concave, we therefore have
\begin{equation}
  \inf_{r\in\bm R} U(r) = - (\bar{r}+r_c) + \min((\beta-1)(\bar{r}-r_c),0)
\end{equation}

We now try to determine the \emph{algorithimically stable} bounds on the two algorithms
derived in the previous section. We first start with the linear algorithm, namely, given a
dataset $S_n$ where, as before, $n=s\times t$, we want to find the largest (in the $\sup$
sense) theoretical difference between the utility observed when investing on a new
datapoint $(x,r)\sim\bm D$ using a decision vector $q_n$ formed from $S_n$ and $q_{n'}$
formed from $S_n\setminus \{(x,r)\}$ where $x$ is chosen at random. In other words, we
simply try to observe how much the utility could be affected by a single
observation. Obviously, the smaller the bound, the better it is since we avoid overfitting
(the algorithm is less dependant on single points).

Mathematically, we want to bound the following expression, where $(x,r)\sim\bm D$. Here,
we use the fact that the absolute first derivative of $U$ is bounded by $1$, and therefore
is a 1-Lipschitz function\cite{lipschitz}:
\begin{align*}
  |U(q_n,x,r) - U(q_{n'},x,r)| = |U(q_n^Tx,r) - U(q_{n'}^Tx,r)| \leq |(q_n - q_{n'})^Tx|
\end{align*}

\begin{deff}[Subgradient and subdifferential]
  Form \cite{rockafellar}, a vector $s$ is said to be a \emph{subgradient} of a convex
  function $f$ at a point $x$ if, for all $y$,
\begin{equation*}
  f(y) \geq f(x) + s^T(y-x).
\end{equation*}
Geometrically, if $s$ is a subgradient of $f$ at $x$, then $h(z) = f(x) + s^T(z-x)$ is an
hyperplane supporting the convex set $\epi f$ at $(x,f(x))$.

The set of all subgradients of $f$ at $x$ is the subdifferential and is denoted
$\dd f(x)$.

\marginnote{TODO!}Reciprocally, we also define \emph{supergradients} the same way as
subgradients, but for concave functions\cite{supergradients}, that is $s$ is a
supergradient to $f$ at $x_0$ if and only if 
\begin{equation*}
  f(x) \leq f(x_0) + s^T(x-x_0).
\end{equation*}
\end{deff}

Because $\hat U$ is the average utility over all data points of $S_n$, $\hat U$ is a
convex function of the decision vector $q$ in $\real^p$, because $U$ is itself convex in
$\real^p$. Let $\dd\hat U$ be the set of supergradients of $\hat U$ at $q^\star$. Then,
for any $s\in\dd\hat U$, the following hold by definition of the supergradient:
\begin{equation}
s^T(q_{n'}-q_n) \geq \hat U(q_{n'},S_n) - \hat U(q_n,S_n).
\end{equation}
In particular, it easy to see that $0\in\dd\hat U$ because $q_n$ is the optimal decision
vector for the information dataset $S_n$. It follows that the following holds:
\begin{equation}
  0 \geq {s^\star}^T(q_{n'} - q_n) \geq  \hat U(q_{n'},S_n) - \hat U(q_n,S_n).
\end{equation}
where
\begin{equation}
  s^\star = \argmin_{s\in\dd\hat U} s^T(q_{n'} - q_n)
\end{equation}


\begin{thebibliography}{99}

\bibitem{rudin2015}
  Cynthia Rudin and Gah-Yi Vahn. \textit{The Big Data Newsvendor: Pratical Insights from
    Machine Learning}, Operations Research, 2015.

\bibitem{lipschitz}
  ``Si la valeur absolue de la dérivée est majorée par $k$, $f$ est $k$-lipschitzienne''.
  \href{https://fr.wikipedia.org/wiki/Application_lipschitzienne}{Application
    lipschitzienne}.

\bibitem{rockafellar}
  Rockafellar, R.~T. \emph{Convex Analysis}, Princeton University Press, 1970.

\bibitem{supergradients}
  \href{http://people.hss.caltech.edu/~kcb/Notes/Supergrad.pdf}{Supergradients}.

\bibitem{refneeded} Reference needed!

\end{thebibliography}
\end{document}
