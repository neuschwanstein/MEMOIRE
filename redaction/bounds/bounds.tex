\section{Garanties statistiques}


La section précédente été dédiée à l'approche algorithmique du problème: comment, donnés
un ensemble d'entraînement et un espace de décision $\Q$, une fonction de décision
$\hat q:\Q \to \Re$ permettant de prescrire un investissment pouvait être déterminée. Cette
section sera consacrée aux garanties statistiques de cette solution. Dans un premier
temps, une étude de la stabilité de l'algorithme d'optimisation permettra de dériver une
borne de généralisation sur la performance hors-échantillon (Section \ref{b:gen}). Par la
suite, le problème sera approché d'un point probabiliste (en terme de variables
aléatoires) afin de comparer les performances de la décision optimale d'investissement sur
$M$ par rapport à la décision empirique (Section \ref{b:sopt}). Enfin, la Section
\ref{b:dim} portera sur l'influence de la dimensionalité de l'espace $\Q$ sur la qualité
des bornes alors obtenues, et don

Les bornes qui seront dérivées n'auront de signification qu'en terme d'\textit{util},
c'est à dire la dimension de $u(r)$ pour un certain rendement. Comme cette notion n'a en
soi aucune signification tangible, un théorème sera finalement introduit afin d'obtenir
pour chacune des bornes une version sous forme de rendement équivalent.


\paragraph{Hypothèses et discussion}

Certaines hypothèses devront d'abord être formulées afin d'être en mesure d'obtenir des
résultats pertinents: ce sera en fait le prix à payer pour l'absence de contraintes sur la
forme de la distribution $M$, notamment concernant par exemple sa covariance ou la forme
de ses moments d'ordre supérieurs.

\begin{assumption}
  L'amplitude de similarité d'une observation est bornée: pour tout $x \in \X$,
  $\kappa(x,x) \leq \xi^2$.
\end{assumption}
\begin{assumption}
  Le rendement aléatoire est borné: $|R| \leq \rmax$.
\end{assumption}
\begin{assumption}
  Un investisseur est doté d'une fonction d'utilité $u$ concave, monotone et standardisée,
  c'est-à-dire que $u(r)|_{r=0} = 0$ et $\partial u(r)|_{r=0} \ni 1$\footnote{Ici,
    $\partial u(r)$ signifie l'ensemble des sur-gradients de $u$. Dans le cas dérivable, cela
    revient à la notion de dérivée. Dans le cas simplement continu, $\partial u(r)$ est
    l'ensemble des fonctions affines ``touchant'' à $u(r)$ et supérieures à $u(r)$ pour
    tout $r$ du domaine). Bien qu'il s'agisse d'un ensemble, la situation désigne souvent
    un sur-gradient optimal par rapport aux autres.}. De plus, $u$ est défini sur
  l'ensemble de $\Re$. Enfin, $u$ est $\gamma$-Lipschitz, c'est-à-dire que pour tout
  $r_1,r_2 \in \Re$, $|u(r_1) - u(r_2)| \leq \gamma|r_1-r_2|$.
\end{assumption}

Avant d'aller plus loin, il convient toutefois de discuter de la plausiblité de ces
contraintes. Cependant, compte tenu de l'aspect central de la première hypothèse, une
discussion approfondie ne sera abordée qu'à la section \ref{b:dim}.

Pour ce qui est de la seconde hypothèse, si on définit les rendements selon
l'interprétation usuelle d'un changement de prix $p$, \ie, $r = \Delta p/p$, on constatera que
$r$ est nécessairement borné par 0. De plus, selon la période de temps pendant laquelle
$\Delta p$ est mesuré, il y a forcément moyen de limiter l'accroissement dans le prix, pour
autant que $\Delta t$ soit suffisament court.

La troisième hypothèse est davantage contraignante. Elle exclut d'emblée plusieurs
fonctions d'utilité courantes; par exemple l'utilité logarithmique et racine carrée
puisqu'elles ne sont définies que pour $\Re_{+}$. Une utilité quadratique, comme celle de
Markowitz est également inadmissible puisqu'elle est non-monotone. Les utilités de forme
exponentielle inverse $u(r) = \mu(-\exp(-r/\mu)+1)$ quant à elles violent la condition
Lipschitz. On peut cependant définir une utilité exponentielle \textit{à pente contrôlée},
c'est à dire dont la pente devient constante lorsque $r \leq r_0$. Par contre, une utilité
qui serait définie par morceaux linéaires est parfaitement acceptable. Par ailleurs, on
considérera souvent l'utilité \textit{neutre au risque} $\bm{1}: r \mapsto r$ comme un cas
limite à l'ensemble des fonctions d'utilité admissibles.


\subsection{Bornes de généralisation}
\label{b:gen}


\paragraph{Exposition du problème}

Soit $\Q$ un espace de Hilbert à noyau reproduisant induit par $\kappa$ et soit un ensemble
d'entraînement $\S_n = \{(x_i,r_i)\}_{i=1}^n \sim M^n$ échantilloné à partir de la
distribution de marché. Alors on peut définir \textit{l'algorithme de décision}
$\alg:\M^n \to \Q$ par
\begin{equation}
  \label{b:basic}
  \alg(\S_n) = \argmax_{q \in \Q} \left\{\widehat\EU(\S_n,q) - \lambda\nq{q}^2\right\}.
\end{equation}

Comme on l'a vu, résoudre \eqref{b:basic} est aussi équivalent à
\begin{equation}
  \maximizeEquation[\alpha \in \Re^n]{n^{-1} \sumi u(r_i\,\alpha^T\phi(x_i)) - \lambda \alpha^TK\alpha,}
\end{equation}
où $\phi:\Re^p \to \Re^n$ le vecteur d'application induit par la matrice d'information $\Xi$. La
relation $q = \alpha^T\phi$ permet de passer d'une représentation à l'autre.

La question qui se pose naturellement est de savoir dans quelle mesure une fonction de
décision $\hat q = \alg(\S_n)$ est capable d'offrir à un investisseur une utilité espérée
comparable à celle qu'il aurait observée au sein de l'ensemble d'entraînement. Il serait
aussi souhaitable qu'une telle garantie soit indépendante de l'ensemble d'entraînement
$\S_n$. Autrement dit, on cherche à déterminer une borne probabiliste $\hat\Omega_u$ sur l'erreur de
généralisation de $\hat q = \alg(\S_n)$ valide pour tout $\S_n \sim M^n$:
\begin{equation}
 \hat\zeta_u(\S_n) \leq \hat\Omega_u(n,\ldots),
\end{equation}
où
\begin{equation}
  \label{b:zeta}
  % \hat\zeta(\hat q) = n^{-1}\sumi u(r_i\,\hat q(x_i)) - \E u(R \cdot \hat q(X))
  \hat\zeta_u(\S_n) =  \hEU(\S_n,\alg(\S_n)) - \EU(\alg(\S_n))
\end{equation}
représente l'erreur de généralisation.

Bien que ces résultats soient intéressants d'un point de vue théorique, on veut d'un point
de vue pratique pouvoir garantir au détenteur du portefeuille un intervalle de confiance
sur l'équivalent certain du portefeuille. On cherchera donc une borne $\hat\Omega_e$ telle que
\begin{equation}
  \CE(\S_n,\alg(\S_n)) \geq \hCE(\S_n,\alg(\S_n)) - \hat\Omega_e(n,\ldots).
\end{equation}

% En fait, on peut démontrer que $\hat\Omega_u = \O(n^{-1/2})$, ce qui permet de quantifier la
% ``vitesse'' à laquelle la convergence à lieu.


\paragraph{Intuition et éléments de preuve}

En fait, la motivation derrière ces hypothèses est la suivante: combinées à l'élément de
régularisation, elles parviennent d'une part à borner la perte que peut entraîner la prise
de décision dans le pire cas et d'autre part à borner la différence entre deux fonctions
de décision entraînées sur des ensembles à peu près identiques.

Considérons deux ensembles d'entraînement: $\S_n \sim M^n$ et $\S'_n$, où $\S'_n$ ne diffère
de $\S_n$ que par un seul point (par exemple le $j$-ème point serait rééchantilloné de la
distribution de marché $M$). De l'algorithme $\alg$ on dérivera alors deux décisions:
$\hat q$ et $\hat q'$. Pour $n$ suffisament grand, on peut alors s'attendre à ce que
l'utilité dérivée de ces deux décisions soit relativement proche, et ce, pour toute
observation. On aurait alors une borne $\beta(n)$ telle que pour tout $(x,r) \sim M$,
\begin{equation}
  |u(r\,\hat q(x)) - u(r\,\hat q'(x))| \leq \beta.
\end{equation}
C'est ce qu'on appelle dans la littérature la \textit{stabilité algorithmique}. La plupart
des algorithmes régularisés classiques disposent par ailleurs d'une telle stabilité. En
particulier, le terme de régularisation $\lambda \nq{q}^2$, combiné à la continuité Lipschitz de
$u$ font en sorte que $\beta = \O(n^{-1})$. Par le Lemme \ref{lem:stab}, p.~\pageref{lem:stab}
(une application directe du théorème de Bousquet), on obtient effectivement
\begin{equation}
  \beta \leq \frac{\gamma^2\rmax^2\xi^2}{2\lambda n}.
\end{equation}

Dotée de cette stabilité de $\alg$, la différence dans l'erreur de
généralisation de $\S_n$ et $\S_n'$ peut alors être bornée:
\begin{align}
  |\hat\zeta(\S_n) - \hat\zeta(\S_n')| &= |\EU(\hat q) - \EU(\hat q') + \hEU(\S_n,\hat q) - \hEU(\S_n',\hat q')|\\
                               &\leq |\EU(\hat q) - \EU(\hat q')| + |\hEU(\S_n,\hat q) -
                                 \hEU(\S_n',\hat q')|. \label{b:p1}                         
\end{align}
Or, par le théorème de Jensen appliqué à la fonction valeur absolue, on obtient du premier
terme que
\begin{align}
  |\EU(\hat q) - \EU(\hat q')| &= |\E(u(R \cdot \hat q(X)) - u(R \cdot \hat q'(X)))|\\
                               & \leq \E(|u(R\cdot \hat q(X)) - u(R \cdot \hat q'(X)|)\\
                               & \leq \beta,
\end{align}
par définiton de la stabilité. Quant au deuxième terme de \eqref{b:p1} on peut le borner
de la même façon:
\begin{align}
  &|\hEU(\S_n,\hat q) - \hEU(\S_n',\hat q')|\\
  &\qquad = n^{-1}\left|\sumi \mathbb{I}_{i\neq j}u(r_i\,\hat q(x_i)) + u(r_j\,\hat q(x_j)) - \sumi
    \mathbb{I}_{i\neq j}u(r_i\,\hat q'(x_i)) - u(r_j'\,\hat q'(x_j'))\right|\\
  &\qquad \leq n^{-1}\left(| u(r_j\,\hat q(x_j) - u(r_j'\,\hat q'(x_j'))| +\sumi \mathbb{I}_{i\neq
    j}\big|u(r_i\,\hat q(x_i)) - u(r_i\,\hat q'(x_i))\big|\right)\\
  &\qquad \leq n^{-1}\left(| u(r_j\,\hat q(x_j) - u(r_j'\,\hat q'(x_j'))| + (n-1)\beta\right).
\end{align}
Considérons le premier terme. Par le Lemme \ref{lem:bqhat}, p.~\pageref{lem:bqhat}, on
sait que $\hat q(x) \leq (2\lambda)^{-1}\rmax\xi^2$ et que $|R|\leq\rmax$. On peut donc borner cette
différence par la différence dans l'utilité dérivée par la meilleure décision
d'investissement sur le meilleur rendement et sur le pire rendement. Par hypothèse
Lipschitz et de sur-gradient de 1 à $r=0$, on sait que pour $r>0, u(r)<r$ et que pour
$r<0$, $\gamma r \leq u(r)$. On peut donc conclure que
\begin{align}
  |u(r_j\,\hat q(x_j) - u(r_j'\,\hat q'(x_j')| &\leq u((2\lambda)^{-1}\rmax^2\xi^2) -
                                                 u(-(2\lambda)^{-1}\rmax^2\xi^2)\\
  & \leq (2\lambda)^{-1}(\gamma+1)\rmax^2\xi^2.
\end{align}
Ce qui entraîne donc que
\begin{align}
  |\hEU(\S_n,\hat q) - \hEU(\S_n',\hat q')| &\leq \frac{\gamma+1}{2\lambda n}\rmax^2\xi^2 +
                                              \frac{n-1}{n}\beta\\
                                            &\leq \beta + \frac{\gamma+1}{2\lambda n}\rmax^2\xi^2,
\end{align}
d'où, après quelques simplifications algébriques, on peut enfin tirer que
\begin{equation}
  |\hat\zeta(\S_n) - \hat\zeta(S'_n)| \leq \beta(2\gamma^2 + \gamma + 1).
\end{equation}
Ainsi la différence dans l'erreur de généralisation est de convergence $\O(n^{-1})$. À ce
stade, la démonstration est presque complète, puisqu'en appliquant l'inégalité de
concentration de McDiarmid, on obtient qu'avec probabilité $1-\delta$:
\begin{equation}
  \hat\zeta(\S_n) < \E_{\S_n}\hat\zeta(\S_n) + \sqrt{\beta(2\gamma^2+\gamma+1)\log(1/\delta)}.
\end{equation}
Or, $\E_{\S_n}\hat\zeta(\S_n) \leq \beta$ (voir \cite{mohri2012foundations} pour une preuve technique
mais complète), d'où on a finalement la borne recherchée:
\begin{equation}
  \hEU(\S_n,\alg(\S_n)) - \EU(\alg(\S_n)) \leq \hat \Omega_u,
\end{equation}
où
\begin{equation}
  \hat\Omega_u = \beta + \sqrt{\beta(2\gamma^2+\gamma+1)\log(1/\delta)} = \O(1/(\sqrt{n}\lambda)).
\end{equation}

\paragraph{Équivalent certain}

Puis inverser pour obtenir l'équivalent certain.

\paragraph{Note bibliographique}

La théorie de la stabilité algorithmique remonte en fait aux années 70 avec les travaux de
Luc Devroye appliqués à l'algorithme des $k$ plus proches voisins\cit. Jusqu'alors, les
bornes de généralisation étaient présentées pour toute décision $q \in \Q$ (ie
Vapnik). Bousquet\cit a été le premier a présenter des résultats dans des espaces de
Hilbert à noyau reproduisant. La démonstration est fortement inspirée de l'excellente
référence Mohri\cit. La démonstration de la borne de la décision bornée est un résultat
inédit, dûe à Delage dans le cas linéaire.


\subsection{Bornes de sous optimalité}
\label{b:sopt}


\paragraph{Exposition du problème}

Jusqu'ici, les efforts théoriques ont été déployés pour déterminer comment se comportait
la fonction de décision $\hat q = \alg(\S_n)$ dans un univers probabiliste par rapport à
l'univers statistique dans lequel elle avait été construite. Notre attention va maintenant
se tourner vers la performance de $\hat q$ dans l'univers probabiliste par rapport à la
meilleure décision disponible, c'est à dire la solution $q^\star$ de 
\begin{equation}
  \maximizeEquation[q \in \Q]{\EU(R \cdot q(X)).}
\end{equation}

Il convient cependant de réaliser que l'existence d'une borne sur $q^\star$ n'est pas
assurée. En effet, supposons d'une part que l'on dispose d'une utilité neutre au risque,
telle que $u(r) = r$, et d'autre part que $\E R=0$. Soit $\alpha>0$. On pourrait alors définir
la fonction suivante:
\begin{equation}
  q = \alpha\E(R\,\kappa(X,\cdot))
\end{equation}
On aurait alors
\begin{align}
  \EU(q) &= \E(R q(X)) = \E(R\E(R\,\kappa(X,X)))\\
         &= \E(R^2\,\kappa(X,X)) \geq 0,
\end{align}
On peut alors obtenir une utilité espérée non bornée à mesure que $\alpha\to\infty$. Par ailleurs,
ainsi défini, $q$ représente effectivement la covariance entre $R$ et la projection de $X$
dans l'espace dual de $\Q$. Puisque l'utilité est neutre, on sait qu'en espérance
l'application de $q$ à $X$ variera de la même façon que celle de $R$ et donc qu'on aura
une utilité infinie. On verra plus loin au cours d'une démonstration la motivation
derrière cette hypothèse supplémentaire:
\begin{assumption}
  L'utilité croît sous-linéairement, ie. $u(r) = o(r)$. 
\end{assumption}

Une autre hypothèse est maintenant nécessaire pour s'assurer que $q^\star$ soit borné:
l'efficience des marchés. Dans notre cadre théorique, ceci se traduit par l'absence de
l'existence d'une fonction $q \in \Q$ telle que
\begin{equation}
  \pp\{R\cdot q(X) > 0\} = 1.
\end{equation}
D'un point de vue strictement financier, cela fait certainement du sens en vertu de
l'efficience des marchés, version semi-forte\cit. D'un point de vue théorique, ceci exige
en fait qu'il n'y ait pas de région dans $\X$ telle que tous les rendements s'y produisant
soient nécessairement positifs ou négatifs.\todo{Inserer image}.

\begin{assumption}
  \label{hyp:arb}
  Pour toute région $\mathcal{R}\subseteq\X$,
  \begin{equation}
    \pp\{R \geq 0 \mid X \in \mathcal{R}\} < 1,
  \end{equation}
  et de la même façon avec l'évènement $\pp\{R \leq 0\}$. 
\end{assumption}

\paragraph{Borne}

On cherchera donc à établir une borne sur \textit{l'erreur de sous-optimalité} de
$\hat q \sim \alg(M^n)$.


\subsection{Garanties et dimensionalité du problème}
\label{b:dim}

Toutes les bornes considérées jusqu'à présent ont été dérivées sans faire apparaître
explicitement la relation qui les lient avec avec la dimension $p$ de l'espace $\Q$. Si à
première vue l'erreur de généralisation et de sous-optimalité du problème de portefeuille
se comporte comme $\O(1/(\lambda \sqrt{n}))$, dans un contexte ou $p$ est comparable à $n$, on
souhaite comprendre comment l'ajout d'information dans $\Q$ peut venir ralentir ces
bornes.



\paragraph{Discussion sur la première hypothèse}


La première hypothèse dépend pour sa part de la forme de $\kappa$. Pour les
espaces de décision affines, par exemple ceux engendrés par les noyaux de la forme
$\kappa(x_1,x_2) = f(\|x_1-x_2\|)$, cette propriété est naturellement observée puisqu'alors
$\kappa(x,x) = f(0)$, peu importe la taille de $\X$. Pour d'autres types de noyaux, par exemple
les décisions linéaires $\kappa(x_1,x_2) = x_1^Tx_2$, il devient alors nécessaire de borner le
support de $X$. Deux approches peuvent alors être employées : soit chaque variable
d'information est bornée individuellement, soit on borne simplement $\kappa(X,X)$ par une borne
probabiliste. 

Le premier cas se prête bien à la situation où on dispose d'une bonne compréhension des
variables d'information et de leur distribution. Par exemple, $X_j$ peut naturellement
reposer sur un support fini; pour d'autres types de distributions, par exemple les
variables normales et sous-normales (dominées stochastiquement par une variable normale),
on peut borner avec un haut degré de confiance la déviation de leur espérance. Les cas
problématiques seront plutôt présentés par des variables $X_j$ présentants des moments
supérieurs élevés. En pratique, on pourra alors soit \textit{saturer} l'information par
une borne arbitraire en ajoutant une dimension d'information vrai/faux indiquant si la
borne a été atteinte, ou simplement décider de l'incorporer telle qu'elle, mais en n'ayant
aucune garantie sur les performances hors échantillon. Pour un noyau linéaire, si chaque
variable $|X_j| \leq \nu_j$, alors par le théorème de Pythagore on a simplement que
$\|X\|^2 \leq \|\nu\|^2 = \xi^2$. On remarquera alors que $\xi^2 = \O(p)$. Pour les noyaux
polynomiaux d'ordre $k$, ce serait plutôt $\xi^2 = \O(p^k)$.

Cette situation où $X$ dispose d'une borne explicite sur son support peut en fait être
relaxée, moyennant que chacune des composantes soient indépendantes l'une à l'autre et que
leur carré soient de forme sous-exponentielle\footnote{Voir Boucheron et/ou Wainwright
  et/ou définir brièvement}. Dans sa forme généralisée, l'inégalité de
Bernstein implique alors que
\begin{equation}
  \pp\{|\|X\|^2 - \E\|X\|^2| \geq t\} \leq \exp\left(\frac{t^2}{\O(p)}\right).
\end{equation}
Autrement dit, à mesure que $p$ est grand, la norme $\|X\|^2$ sera concentrée autour de
son espérance. Si $\E X_j=0$, alors $\E\|X\|^2 = \sumj \Var X_j = \O(p)$, et on aura donc
une borne $\xi^2 = \O(p)$, mais nettement plus forte que celle considérée au dernier
paragraphe, puisque la composante $\|\nu\|^2$ devient inutile.


\todo{Montrer que la borne est proportionelle à $\max R\cdot q(X)$.}


\paragraph{Introduction au cas linéaire}

Pour le moment, nous allons considérer le cas plus simple où $\Q = \X^*$, c'est à dire que
le problème revient simplement à 
\begin{equation}
  \maximizeEquation[q \in \Re^p]{n^{-1}\sumi r_i\,q^Tx_i - \lambda\|q\|^2.}
\end{equation}
Pour simplifier la présentation, une utilité neutre au risque sera considérée comme cas
limite au problème plus général (voir lemme de borne\cit).

D'un point de vue probabiliste, on peut définir $\qsh$ comme la solution de
\begin{equation}
  \maximizeEquation[q \in \Re^p]{\E(R\,X^Tq) - \lambda\|q\|^2,}
\end{equation}
d'où on tire
\begin{equation}
  q^\star_\lambda = \frac{1}{2\lambda}\Cov(R,X),
\end{equation}
puisque les deux variables sont centrées. On retrouve alors l'inégalité montrée en lemme
\cit (nécessaire??)
Considérons maintenant $P$ le rendement aléatoire obtenu en utilisant la décision $\qsh$:
\begin{equation}
  P = \frac{1}{2\lambda}R\,X^T\Cov(R,X).
\end{equation}
On a alors $\E P = 1/2\lambda\,\Cov^2(R,X)$.

Puisque toutes nos variables sont centrées et réduites,
\begin{equation}
  \Cov(R,X) = \sumj\E R\,X_j.
\end{equation}

En supposant que notre problème est pleinement déterminé en supposant l'existance d'une
matrice $A$ telle que $R = AX$



\input{lemmas}




%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main_bounds"
%%% End:
