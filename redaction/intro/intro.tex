\section{Introduction}

\subsection{Exposition du problème et hypothèses}

Ce mémoire vise à établir clairement et rigoureusement comment un investisseur
\textit{averse au risque} disposant \textit{d'information complémentaire} au
\textit{marché} peut utiliser cette information pour accroître son \textit{utilité
  espérée} ou, de façon équivalente, son \textit{rendement équivalent certain}.

\paragraph{Modélisation du marché}

Nous entendrons ici par \textit{marché} n'importe quel type d'actif financier ou
spéculatif dans lequel on peut investir une partie de sa fortune dans l'espoir de la voir
fructifier au cours d'une période de temps arbitraire. Ainsi, tout au long de l'exposé
théorique qui suivra, il peut être pertinent d'avoir en tête les rendements quotidiens
issus des grands indices boursiers (par exemple les 500 plus grandes capitalisations
américaines). Cependant, le traitement qui sera développé pourrait tout aussi bien
s'appliquer à une action cotée en bourse dont on considère les rendements mensuels.\nec
Mathématiquement, l'idée de marché peut ainsi être réduite à celle d'une variable
aléatoire $R(t)$ décrivant l'évolution du rendement de l'actif en question.

Relativement à l'idée de marché, nous ferons également l'hypothèse que l'univers a une
influence sur ces rendements. Il serait par exemple raisonnable de croire que le prix du
pétrole a une influence sur l'évolution du rendement du marché américain. De la même
façon, l'annonce d'un scandale aura a son tour des répercussions sur la valeur du titre de
la compagnie dont il est l'objet. En outre, il a été montré par Fama et French que le
rendement d'une action pouvait s'expliquer comme une combinaison de quelques facteurs
fondamentaux (la taille de l'entreprise, le risque de marché et le ratio cours/valeur). On
peut alors considérer un vecteur d'information $\vec X(t) = (X_1(t), X_2(t), \dots)$ dont
chaque composante représente une information particulière, par exemple l'absence ou la
présence d'un certain type de scandale, un ratio comptable, le prix d'un certain actif
financier\reph. D'un point de vue probabiliste, on dira donc qu'il existe une forme de
dépendance entre $R(t)$ et $\{\vec X(\tau) \mid \tau < t\}$ l'ensemble des évènements antérieurs à
$t$. Le processus joint de ces deux évènements sera désormais défini comme \textit{la
  distribution totale de marché}, ou simplement le marché.


\paragraph{Stationarité}

Bien qu'un tel modèle permette de représenter de façon très générale l'évolution d'un
marché, nous formulerons l'hypothèse supplémentaire selon laquelle le marché est un
processus \textit{stationnaire}. Ceci permet notamment d'évacuer la notion temporelle afin
de ne représenter qu'une distribution de causes (l'information $X$) et d'effet
(l'observation des rendements $R$). Cette hypothèse est assez contraignante. Elle suppose
d'une part que les réalisations passées n'ont aucun effet sur les réalisations futures
(indépendance) et d'autre part que la distribution de marché est figée dans le temps, ce
qui implique notamment l'absence de probabilité de faillite. Elle implique aussi que le
marché ne peut être vu comme un environnement adversariel qui réagirait par exemple aux
décisions d'un investisseur. Ceci vient notamment mettre en cause la théorie des marchés
efficients selon laquelle une brèche dans l'absence d'arbitrage serait immédiatement
colmatée par des spéculateurs (effet d'autorégulation). Nous aurons toutefois l'occasion
de revenir plus en détail sur les liens à faire entre cet exposé et l'efficience des
marché.

\paragraph{Approche mathématique et statistique}

Dans ce qui suit, nous noterons par $M$ la distribution de marché. Le vecteur aléatoire
d'information sera par ailleurs formé de $m$ composantes; pour l'instant, aucune hypothèse
par rapport à la dépendance des composantes de $X$ ne sera formulée. À ce point-ci, on a
donc le modèle de marché suivant:
\begin{equation}
  M = (R,X_1, \ldots, X_m).
\end{equation}

On fera également l'hypothèse qu'on possède un ensemble de $n$ éléments échantillonés à
partir de $M$, de sorte que:
\begin{equation}
  \{r_i, x_{i1}, \ldots, x_{im}\}_{i=1}^n \sim M
\end{equation}
représente notre ensemble d'échantillonage (aussi appelé ensemble d'entraînement). Le
domaine des rendements possibles de $R$ sera noté $\R \subseteq \Re$ et celui du vecteur
d'information $X$ sera noté $\X \subseteq \Re^m$. Le vecteur d'observations de rendement sera noté
$r \in \Re^n$ et la matrice d'information par $X \in \Re^{n \times m}$.



\paragraph{Modélisation de la préférence}

Indépendamment de la notion de marché, on a d'autre part l'aspect d'aversion au risque qui
est modélisé par une fonction d'utilité $u:\R\to\U$, où $\R \subseteq \Re$ est le domaine (fermé ou
non) des rendements considérés et $\U \subseteq \Re$ celui des \textit{utilités}.

Bien qu'en pratique il soit plus facile de travailler sur des fonctions possédant des
valeurs dans $\U$, en pratique cet espace est adimensionel\cit, de sorte que nos résultats
seront présentés dans l'espace des rendements $\R$.


\paragraph{Fonction de décision}

Donnés ces éléments de base, le but de ce mémoire sera alors de déterminer une fonction de
décision d'investissement $q: \X \to \P \subseteq \Re$ maximisant l'utilité espérée de l'investissement.

Mathématiquement on a donc le problème fondamental suivant:
\begin{equation}
  \maximizeEquation[q \in \Q]{\E u(R \cdot q(X)),}
\end{equation}
où l'optimisation a lieu dans un espace de fonctions $\Q$ à préciser.

Cependant, comme la distribution $(X,R) = M$ est inconnue, il est impossible de déterminer
la fonction $q^\star$ minimisant cet objectif. On dispose toutefois d'un échantillon de
$M$ dont on peut se servir pour approximer le problème (SAA, voir Shapiro\cit):
\begin{equation}
  \maximizeEquation[q \in \Q]{n^{-1} \sumi u(r_i\, q(x_i)),}
\end{equation}
mais encore ici le problème est mal spécifié, puisqu'aucune contrainte n'a été posée sur
l'espace $\Q$. Par exemple, il suffirait de prendre pour $q$ un dictionnaire associant à
$x_i$ la valeur $\alpha\,r_i$, où $\alpha > 0$, et à toute autre valeur de $x$ une valeur nulle pour
avoir une valeur d'utilité arbitrairement grande à mesure que $\alpha \to \infty$.


\paragraph{Risque in-échantillon et hors échantillon}

 une telle fonction $q$ est qu'elle se généralise très mal. En effet
pour toute observation $x$ qui ne figurerait dans l'ensemble d'entraînement, $q$
prescrirait alors un investissement nul. Il y a alors une énorme différence entre
l'utilité observée au sein de notre échantillon et l'utilité hors échantillon.

Donnée une fonction de décision $q \in \Q$ et un échantillon de $M$, on définit le
\textit{risque in-échantillon} ou \textit{risque empirique} par
\begin{equation}
  \hat R(q) = n^{-1}\sumi \ell(r_i\,q(x_i)),
\end{equation}
où $\ell = -u$. De la même façon, on définit le \textit{risque hors-échantillon} ou
\textit{erreur de généralisation} par
\begin{equation}
  R(q) = \E \ell(R \cdot q(X)).
\end{equation}
On peut souhaiter d'une bonne fonction de décision qu'elle performe bien hors échantillon,
aussi la quantité $R(q) - \hat R(q)$ sera-t-elle primordiale et beaucoup d'attention lui
sera consacrée dans les prochaines sections. Notons que le risque hors-échantillon étant
théoriquement impossible à calculer, en pratique on segmentera l'ensemble d'échantillonage
en deux parties, l'une dédiée à l'apprentissage, l'autre à évaluer la performance hors
échantillon.


\paragraph{Régularisation}

Afin de contrecarrer le risque hors échantillon, la solution est en fait de pénaliser la
complexité de la fonction de décision $q$ (rasoir d'Occam). Ainsi, on étudiera en
profondeur le choix d'une fonctionelle $R : Q \to \Re$ permettant de quantifier la complexité
de $q$. L'objectif serait alors
\begin{equation}
  \maximizeEquation[q \in \Q]{n^{-1} \sumi u(r_i\, q(x_i)) - R(q).}
\end{equation}
Par exemple, comme les mesures sur $x$ peuvent comporter de l'incertitude ou du bruit, il
serait souhaitable que la décision $q(x_1)$ soit proche de $q(x_2)$, si $x_1$ et $x_2$
sont eux même proches dans l'espace $\X$. Si $R$ encodait une telle préférence, ne
fonction discontinue comme le dictionnaire présenté plus haut sera alors hautement
défavorisée, et une fonction plus lisse y serait préférée.

\todo{Introduire la validation croisée ainsi que le paramètre $\lambda$ dans l'objectif.}



\paragraph{Espaces de décision}

En pratique, ce mémoire ne considérera que des espaces de Hilbert pour $\Q$. Un des
avantages des espaces de Hilbert, c'est qu'ils induisent naturellement une notion de norme
$\|\cdot\|_H$, qu'on peut intuitivement relié au concept de complexité. Nous nous
intéresserons donc aux propriétés induites par $R(q) = \|q\|_H^2 = \langle q, q \rangle$. Il y a
aussi moyen, sous des conditions assez techniques (théorème de la représentation) de
généraliser la norme $L_2$ de $q$ à une norme $L_p$ général. En particulier, nous verrons
qu'une régularisation donnée par norme $L_1$ induit certaines propriétés d'éparsité dans
la solution.


\paragraph{Décisions linéaires}

De façon générale, la forme de décision la plus simple est celle qui combine linéairement
les $p$ observations de $x \in \X \subseteq \Re^p$; autrement dit lorsque qu'on contraint
$\Q = \X^*$, \ie, à l'espace dual de $\X$. En langage plus clair, à toute fonction
$q \in \Q$ il existe un vecteur de dimension $p$ tel que la décision dérivée de
l'observation $x$ sera donnée par $q(x) = \langle q, x \rangle = q^Tx$.

La régularisation $L_2$ de $q$ devient alors tout simplement $R(q) = q^Tq = \|q\|^2$ et la
fonction optimale de décision $q^\star$ sera alors déterminée en résolvant le problème
d'optimisation suivant:
\begin{equation}
  \maximizeEquation[q \in \Re^p]{n^{-1}\sumi u(r_i\,q^Tx_i) - \lambda \|q\|^2.}
\end{equation}



\subsection{Dimensionalité de l'information}

\todo{Discussion du phénomène big data, de l'importance de $p$}



\subsection{Risque et garanties statistiques sur la décision}
\todo{Discussion sur les méthodes de risques hors échantillon, complexité de
  l'échantillonage, mesure Rademacher, distance par rapport à la ``meilleure'' décision}



\subsection{Interprétations}

\paragraph{Interprétation géométrique dans l'espace $X$}

\paragraph{Interprétation statistique (avec matrix covariance)}

\par\paragraph{Autre?}



\subsection{Objectifs}





%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main_intro"
%%% End:
