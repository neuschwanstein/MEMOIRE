
\documentclass[11pt]{article}

\newcommand{\ts}{\textsuperscript}
\newcommand{\figref}[1]{Fig.~\ref{#1}}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{graphicx}
\usepackage{geometry}
\usepackage{subcaption}
\usepackage{bm}
\usepackage{hyperref}
\usepackage[retainorgcmds]{IEEEtrantools}
\usepackage{mathtools}
\usepackage{color}
\usepackage{marginnote}
\usepackage[utf8]{inputenc}


\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator{\st}{s.t.}
\DeclareMathOperator{\epi}{epi}
\DeclareMathOperator{\diag}{diag}
\DeclareMathOperator{\dom}{dom}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}

\newcommand{\iso}{\simeq}
\newcommand{\dd}{\partial}
\newcommand{\real}{\bm R}


\newcommand{\hilight}[1]{\colorbox{yellow}{#1}}
\let\oldmarginnote\marginnote
\renewcommand{\marginnote}[1]{\oldmarginnote{\footnotesize\emph{#1}}[0cm]}

\theoremstyle{plain}
\newtheorem{prop}{Proposition}
\newtheorem{thm}{Theorem}

\theoremstyle{definition}
\newtheorem*{deff}{Definition}
\newtheorem*{rem}{Remark}


\geometry{letterpaper}
\IEEEeqnarraydefcolsep{0}{\leftmargini}

\title{Portfolio Optimization in a Big Data Context}
\author{Thierry \textsc{Bazier-Matte}}
\date{Summer 2015}

\begin{document}
\maketitle

\begin{abstract}
  Following \cite{rudin2015}, we provide a portfolio optimization method based on machine
  learning methods.
\end{abstract}


\section{Introduction}
\label{sec:intro}

\marginnote{Maybe considerations about the length of the period should be added? For
  example, it's not specified what's the period length of $R_f$.}  This document considers
a two-asset portfolio, of which one is the risk-free asset, yielding a constant return
rate $R_f$, and the other being a risky asset $s$, typically a stock, yielding a random
return rate $r_{st}$ for each period $t$. We suppose that each risky asset $s$ can be
decribed daily by an \emph{information vector} $x_{st}$ containing potentially useful
information, such as technical, fundamental or news-related information. Furthermore, we
assume that the allocation of each asset of the portfolio $p_{st}$ can be fully determined
using a \emph{decision vector} $q$. The allocation rule is the folowing: $q^Tx_{st}$ is
allocated to the risky asset and $1-q^Tx_{st}$ is allocated to the risk-free asset. Over
the period $t$, the portfolio $p_{st}$ consisting of asset $s$ will therefore yield a
return rate of:
\begin{equation}
  p_{st}(q) = r_{st}q^Tx_{st} + (1-q^Tx_{st})R_f.
\end{equation}

The question we now wish to ask is how the decision vector $q$ should be chosen. We assume
we have access to a training dataset $S_n$, comprising of $s$ different assets over
$t$\marginnote{What's the difference between having $n$ points with having $s\times t$
  points? For example, what if $s\gg t$ or the reverse?} periods, such that
$n = s\times t$. 



\section{Definitions and Bounds}

\subsection{Definitions Notation}

Most of the following notation and defintions follow directly from \cite{bousquet2002}.

Let $S_n$ be a set of $n$ vectors of $\real^p\times\real$ of the form:
\begin{equation}
  S_n = \{(x_1,r_1),\ldots,(x_n,r_n)\}.
\end{equation}
Each component of $S_n$ is a tuple $(x,r)$, where $x$ is the information vector and $r$ is
the observed return rate.

Using $S_n$, we wish to create a decision vector $q_{S_n}\in\real^p$ from which we can
make an investment decision when confronted with a random draw $d=(x,r)$.

\paragraph{Loss, cost and regret.}
We introduce the loss $\ell$ as being a function mapping from the space of the decision
vectors and full observations (including market observations and the return of the asset)
to a numerical quantity called the cost. Formally, given $q$ a decision vector and a
random draw $d=(x,r)$, the loss will be
\begin{equation}
\ell(q,d) = c(q(x),r) = c(q^Tx,r).
\end{equation}

Supposing an utility $U$, there are two different cost functions we can use. The first
one, and perhaps the most obvious one is defined by
\begin{equation}
  c(p,r) = -U(pr + (1-p)R_f).
\end{equation}
If the utility is piecewise linear, then the cost is not bounded, and so an infinite
return would yield a negatively infinite cost. This means that risk-taking will be
encouraged since risky position, ie. $|p|>1$ can in fact yield a negative cost. On the
other hand, with an unbounded utility, the algorithm minimizing the cost over the sample
must have $\lambda > 0$, otherwise the problem might be unconstrained. \textbf{Unless we
  add a constant piece if $r<\bar r$.}

We can also define a new cost function that is always non-negative, that we shall call the
regret $\rho$ of the decision:
\begin{equation}
  \rho(p,r) =
  \begin{cases}
    \lfloor U(r) - U(pr + (1-p)R_f)\rfloor & \text{if } r>R_f\\
    \lfloor U(R_f) - U(pr + (1-p)R_f)\rfloor &\text{if } r\leq R_f,
  \end{cases}
\end{equation}
where by $\lfloor \cdot \rfloor$ we mean $\max(.,0)$. In the case of exponential
utilty, this cost function is actually equivalent to the one previously defined, but is
quite different in the case of an unbounded utility function, for example the piece-wise
linear one. Such a cost does not encourage risky position, since the cost is at least
0. This means that if $r>0$, then there's no point having $p>1$ instead of $p=1$ since
both will yield a zero cost position. 

\paragraph{Utility.}
There are two ways we can model our utility, and both are concave shaped, to represent a
risk-averse approach. The first utility is the linear utility of the form
\begin{equation}
  U(r) = r + \min(0, \beta r),
\end{equation}
with $0<\beta<1$. The other utility is exponential:
\begin{equation}
  U(r) = -\exp(-\mu r),
\end{equation}
with $\mu > 0$.

\begin{figure}
  \centering
  \begin{subfigure}{.4\textwidth}
  \includegraphics[width=1.1\textwidth]{ExpULossAboveZero.pdf}
\end{subfigure}%
\begin{minipage}{.4\textwidth}
  \includegraphics[width=1.1\textwidth]{ExpULossBelowZero.pdf}
\end{minipage}
\end{figure}

\paragraph{Algorithm.}
We will be concerned with probabilistic confidence bounds on results produced using the
following algorithm, using dataset $S_n$. We shall denote this algorithm as $A_{S_n}$.
\begin{equation}
  \label{algo}
  q^\star = \argmin_{q\in\real^p}\frac{1}{n} \sum_{i=1}^{n} c(q^Tx_i,r_i) + \lambda\|q\|^2_2.
\end{equation}

\paragraph{Assumptions.}
We will assume that information vectors have been pre-processed and lie in a $X^2_{\max}$
radius ball. We also assume that the return rates observed are comprised within $[-\bar r,
\bar r]$. This last assumption will be relaxed. 

\subsection{Definitions, Theorems and Tools}
We now state a certain number of definitions and theorems that will be of great importance
in the analysis on the results produced by the algorithm mentioned above. These
definitions and theorems are taken verbatim from \cite{bousquet2002}.

\begin{deff}
  An algorithm $A$ has \textit{uniform stability} $\beta$ with respect to the loss
  function $\ell$ if, for all $S_n\in\bm D^n$ and $i\in\{1,\ldots,n\}$, the following
  holds:
  \begin{equation}
    \|\ell(A_{S_n},.) - \ell(A_{S^{\backslash i}_n},.)\|_{\infty} \leq \beta_n,
  \end{equation}
  or, equivalently,
  \begin{equation}
    \sup_{d\in\bm D}|\ell(A_{S_n},d) - \ell(A_{S^{\backslash i}_n},d)| \leq \beta_n.
  \end{equation}
  Here, $S^{\backslash i}_n$ means the set $S_n$ with the $i$th data point removed.

  Furthermore, $A$ is \textit{stable} when $\beta_n = O(1/n)$.
\end{deff}

\begin{deff}
  A loss function $\ell$ is \textit{$\sigma$-admissible} if the associated cost function
  $c$ is convex with respect to its first argument and the following condition holds for
  any $p_1,p_2$ and $r$:
  \begin{equation}
    |c(p_1,r) - c(p_2,r)| \leq \sigma |p_1 - p_2|.
  \end{equation}
  It is easy to see that if $\dom c(\cdot,r)$ is bounded and $c(\cdot,r)$ does not reach
  infinity, then its loss function is $\sigma$-admissible.
\end{deff}

\begin{thm}
  \label{thm1}
  Let $F$ be a reproducing kernel Hilbert space with kernel $\kappa$ such that
  $\forall x\in X$, $\kappa(x,x) \leq \kappa^2 <\infty$. If $\ell$ is $\sigma$-admissible
  with respect to $F$, then the learning algorithm defined by
  \begin{equation}
    \label{eq:above3}
    A_S = \argmin_{g\in F}\frac{1}{n}\sum_{i=1}^n \ell(g,d_i) + \lambda\|g\|^2_k
  \end{equation}
  has uniform stability $\alpha_n$ with respect to $\ell$ with
  \begin{equation}
    \alpha_n \leq \frac{\sigma^2 \kappa^2}{2\lambda n}.
  \end{equation}
\end{thm}

\begin{deff}
  The \emph{true risk} with respect to algorithm $A$ and set $S_n$ is defined as
  \begin{equation}
    R_{\text{true}}(A,S_n) = E_d[\ell(A_{S_n},d)],
  \end{equation}
  which is, in plain words, the expected loss incured when applying the algorithm created
  from training set $S_n$ in the wild, ie. out of sample.
\end{deff}

\begin{deff}
  The \emph{empirical risk} with respect to algorithm $A$ and set $S_n$ is defined as
  \begin{equation}
    \hat R(A,S_n) = \frac{1}{n} \sum_{i=1}^n \ell(A_{S_n},d_i),
  \end{equation}
  which is, in plain words, the average cost incured by our model over all the training
  set.
\end{deff}

\begin{thm}
  \label{thm2}
  Let $A$ be an algorithm with uniform stability $\alpha_n$ with respect to a loss
  function $\ell$ such that $0\leq\ell(A_{S_n},d)\leq M$ for all $d=(x,r)\sim D$ and all sets
  $S_n$ of size $n$. Then for any $n\geq1$ and any $\delta\in(0,1)$, the following bound
  holds with probability at least $1-\delta$ over the random draw of the sample $S_n$:
  \begin{equation}
    |R_{\mathrm{true}}(A,S_n) - \hat R(A,S_n)| \leq 2\alpha_n + (4n\alpha_n + M) \sqrt{\frac{\log(2/\delta)}{2n}}.
  \end{equation}
\end{thm}

\subsection{Remarks and applications to our algorithm}

In this section we shall derive bounds on the proposed algorithms concerned with the
difference between the in-sample average cost using the decision vector determined by our
algorithm with the (theoretical) expected cost over the whole distribution when using the
same decision vector. 

The analysis will be done in two parts, one for each of our cost functions: first with
$c=-U$ (the canonical cost) and second with the cost function as the regret at each
decision. Both are quite similar in their results. 

\subsubsection{Canonical cost.}

We first consider the case where 
\begin{equation}
  c(p,r) = -U(pr + (1-p)R_f).
\end{equation}

\begin{rem}[$\sigma$-admissibility]
  We first remark that both forms of $U$ yield a convex function of $p$ with $r$ fixed,
  since $U$ is concave. 

  Next, the expression $|c(p_1,r)-c(p_2,r)|$ reduces to
  \begin{equation}
    \label{eq:above1} |U(p_1r + (1-p_1)R_f) - U(p_2r + (1-p_2)R_f|.
  \end{equation} Now because $r\in[-\bar r,\bar r]$, $U$ is Lipschitz continuous on its
domain, and so \eqref{eq:above1} is bounded by
  \begin{equation}
    \label{eq:above2} \alpha |p_1r + (1-p_1)R_f - (p_2r + (1-p_2)R_f)| =
\alpha|p_1-p_2||r-R_f|
  \end{equation} where
  \begin{equation} \alpha = \sup_{r\in[-\bar r,\bar r]} |U'(r)|.
  \end{equation}

  In the linear case, the derivative is piecewise constant, and is set to 1 on for returns
below $r_c$, so that $\alpha=1$. In the exponential case, $U'(r) = \exp\mu r$, and $\alpha
= \exp \mu \bar r$.

  The bound \eqref{eq:above2} must hold for any $r$. The expression $|r-R_f|$ will reach
  its largest value at $r=-\bar r$, since $R_f$ is assumed to be non-negative, and
  therefore 
  \begin{equation}
    |c(p_1,r) - c(p_2,r)| \leq \alpha (\bar r + R_f)|p_1-p_2|,
  \end{equation}
  which shows that $\ell$ is $\sigma$-admissible with the canonical cost, with
  $\sigma=\alpha(\bar r+ R_f)$.

  We also remark that the utility is actually invariant to scaling, ie. $\tilde{U} = kU$
  where $k$ is positive yields the same relative utility. The $\sigma$ bound can therefore
  be as tight as desired, since it can be scaled by an arbitrary positive constant, and
  the algorithm will yield the same result.
\end{rem}

\begin{rem}[Algorithmic Stability]
  Because the loss function is $\sigma$-admissible, the conditions for Theorem \ref{thm1}
  are respected: if we take the kernel on the space $\real^p$ as the regular inner
  product, than $\kappa(x,x)\leq X^2_{\max}$. Therefore, our algorithm has algorithmic
  stability with:

  \begin{equation}
    \alpha_n \leq \frac{k^2(\bar r+R_f)^2X^2_{\max}}{2\lambda n}
  \end{equation}
  with linear utility and
  \begin{equation}
    \alpha_n \leq \frac{k^2 \exp(2\mu\bar r)(\bar r + R_f)^2 X^2_{\max}}{2\lambda n}
  \end{equation}
  in the case of exponential utility.

  \marginnote{How can we leverage $k$?}
  As discussed above, $k>0$ is a scaling term we can add to the utility function, with
  which we can actually have algorithmic stability as tight as needed. 
\end{rem}

\begin{rem}[Generalization Bound]
  Using Theorem \ref{thm2}, we can derive an out-of-sample bound on the result produced by
  our algorithm for each utility forms that holds with probability $1-\delta$, for
  $0<\delta<1$. The $M$ value stated by Theorem \ref{thm2} corresponds to the highest loss
  we can incur on the domain, which happens when $p=1$ and $r=-\bar r$, ie.
  \begin{equation}
    M = c(1,-\bar r) = -U(\bar r).
  \end{equation}

  In the linear utility case, 
  \begin{align}
    &|R_{\mathrm{true}}(A,S_n) - \hat{R}(A,S_n)| \leq 2\alpha_n + (4n\alpha_n +
      M)\sqrt{\frac{\log(2/\delta)}{2n}}\\
    &\qquad \leq \frac{k^2(\bar r+R_f)^2X^2_{\max}}{\lambda n} + \left(\frac{2k^2(\bar r+R_f)^2X^2_{\max}}{\lambda} + M\right)\sqrt{\frac{\log(2/\delta)}{2n}},
  \end{align}
  and in the exponential utility case, 
  \begin{align}
    &|R_{\mathrm{true}}(A,S_n) - \hat{R}(A,S_n)| \leq 2\alpha_n + (4n\alpha_n +
      M)\sqrt{\frac{\log(2/\delta)}{2n}}\\
    &\qquad \leq \frac{k^2 \exp(2\mu\bar r)(\bar r + R_f)^2 X^2_{\max}}{\lambda n} + \left(\frac{2k^2 \exp(2\mu\bar r)(\bar r + R_f)^2 X^2_{\max}}{\lambda} + M\right)\sqrt{\frac{\log(2/\delta)}{2n}}.
  \end{align}
\end{rem}

\begin{rem}[Absolute Bound]
  Finally, we derive a measure of performance when we compare $\hat q=A_{S_n}$ with the true
  optimal $q^\star$ over the distribution, and how each perfom when applied on the true
  risk of the distribution\ldots
\end{rem}

\subsubsection{Regret cost.}

We now turn our attention toward the regret cost, ie.
\begin{equation}
  c(p,r) = \floor{U(\max(r,R_f)) - U(pr + (1-p)R_f)}.
\end{equation}
This type cost is different from the canonical cost in that to does not encourage `risky'
position for which $0<p<1$, since there's no gain in over-investing our portfolio in a
winning asset. Conversely, there's no gain in shorting a losing asset. Such a cost could
therefore be more suitable in a conservative environment, even if the results produced by
the algorithm $A$ might very well yield a position $0<p<1$.

\begin{rem}[$\sigma$-admissibility]
  The $\sigma$-admissibility of the regret cost follows closely from the
  $\sigma$-admissibility of the canonical cost derived above. Indeed, we remark that,
  provided that $c(p_1,r), c(p_2,r) > 0$, then the expression $|c(p_1,r) - c(p_2,r)|$
  reduces to 
  \begin{equation}
    |U(p_1r + (1-p_1)R_f) - U(p_2r + (1-p_2)R_f)|,
  \end{equation}
  wich has exactly the same form as \eqref{eq:above1}, and therefore yields the same
  $\sigma$ bound. Now for the case where, without loss of generality $c(p_2,r) = 0$. Let
  $\tilde c$ be defined as $c$, but without $\floor{\cdot}$, so that
  $\floor{\tilde{c}(p,r)} = c(p,r)$. In particular $\tilde c(p_2,r)<0$ and so
  \begin{align}
    |c(p_1,r) - c(p_2,r)| &= |\floor{\tilde c(p_1,r)} - \floor{\tilde c(p_2,r)}|\\
    &\leq |\tilde c(p_1,r) - \tilde c(p_2,r)|\\
    &= |U(p_1r + (1-p_1)R_f) - U(p_2r + (1-p_2)R_f)|,
  \end{align}
  which has again the the same form as \eqref{eq:above1}.

  This means that the loss defined with the regret cost has the same
  $\sigma$-admissibility as the loss defined with the canonical cost, namely 
  \begin{equation}
    \sigma = k(\bar r + R_f)
  \end{equation}
  in the case of linear utility and 
  \begin{equation}
    \sigma = k(\bar r+R_f) \exp(\mu\bar r)
  \end{equation}
  in the case of exponential utility. 
\end{rem}

\begin{rem}[Algorithmic Stability]
  Because this regret cost has the same $\sigma$-admissibility as the canonical cost, then
  the algorithmic stability also remains the same for both algorithm, ie.
  \begin{equation}
    \alpha_n \leq \frac{k^2(\bar r+R_f)^2X^2_{\max}}{2\lambda n}
  \end{equation}
  with linear utility and
  \begin{equation}
    \alpha_n \leq \frac{k^2 \exp(2\mu\bar r)(\bar r + R_f)^2 X^2_{\max}}{2\lambda n}
  \end{equation}
  in the case of exponential utility.
\end{rem}

\begin{rem}[Generalization Bound]
  Likewise, the only difference here with the canonical cost is the value of the $M$
  variable of Theorem \ref{thm2}, defined as the highest cost on the domain. In the case
  here, this value is again reached for an investment $p=1$ on a losing asset at $r=-\bar
  r$, so that,
  \begin{equation}
    M = \floor{U(R_f) - U(\bar r)}.
  \end{equation}

  We are left with the same expression for the generalization bounds, in the linear
  utility case,
  \begin{align}
    &|R_{\mathrm{true}}(A,S_n) - \hat{R}(A,S_n)| \leq 2\alpha_n + (4n\alpha_n +
      M)\sqrt{\frac{\log(2/\delta)}{2n}}\\
    &\qquad \leq \frac{k^2(\bar r+R_f)^2X^2_{\max}}{\lambda n} + \left(\frac{2k^2(\bar r+R_f)^2X^2_{\max}}{\lambda} + M\right)\sqrt{\frac{\log(2/\delta)}{2n}},
  \end{align}
  and in the exponential utility case, 
  \begin{align}
    &|R_{\mathrm{true}}(A,S_n) - \hat{R}(A,S_n)| \leq 2\alpha_n + (4n\alpha_n +
      M)\sqrt{\frac{\log(2/\delta)}{2n}}\\
    &\qquad \leq \frac{k^2 \exp(2\mu\bar r)(\bar r + R_f)^2 X^2_{\max}}{\lambda n} + \left(\frac{2k^2 \exp(2\mu\bar r)(\bar r + R_f)^2 X^2_{\max}}{\lambda} + M\right)\sqrt{\frac{\log(2/\delta)}{2n}}.
  \end{align}
\end{rem}


\paragraph{Things to consider.}

Here are some points that should be considered.

\begin{itemize}
\item We have assumed so far we were dealing with datasets taken iid. But in a financial
  setting, this is not necessarily the case, as influence of features might be changing
  with time. (HMM?)
\item In the newsvendor article, the generalization bounds actually hold with probability
  $1-\delta - n\gamma$, if we assume $\bar D$ (the highest considered demand) holds with
  probability $1-\gamma$. It is only mentioned in the non-regularized case. A reference
  would be needed, as the $n\gamma$ terms grows up too quickly to be of any use (unless
  we're being very restrictive on $X_{\max}$).
\item We are also considering discrete quantities, updated daily. Our model should
  encompass quantities that might change during the day.
\end{itemize}




% \newpage
% \begin{rem}
%   Our loss function $\ell$ is $\sigma$-admissible with $\sigma=\bar r+R_f$ in the linear
%   case and $\sigma=(\bar r+R_f)\exp(\mu\bar r)$ in the exponential case.
% \end{rem}

% \begin{proof}
%   First, we remark that both forms of $U$ yield a convex function of $p$ with $r$ fixed. 
%   Now we'll suppose that $c(p_1,r), c(p_2,r) > 0$. Then the expression
%   $|c(p_1,r)-c(p_2,r)|$ reduces to
%   \begin{equation}
%     |U(p_1r + (1-p_1)R_f) - U(p_2r + (1-p_2)R_f|.
%   \end{equation}
%   Now because $r\in[-\bar r,\bar r]$, $U$ is Lipschitz continuous on its domain, and so
%   \eqref{eq:above1} is bounded by
%   \begin{equation}
%     \alpha |p_1r + (1-p_1)R_f - (p_2r + (1-p_2)R_f)| = \alpha|p_1-p_2||r-R_f|
%   \end{equation}
%   where
%   \begin{equation}
%     \alpha = \sup_{r\in[-\bar r,\bar r]} |U'(r)|.
%   \end{equation}

%   In the linear case, the derivative is piecewise constant, and is set to 1 on for returns
%   below $r_c$, so that $\alpha=1$. In the exponential case, $U'(r) = \exp\mu r$, and
%   $\alpha = \exp \mu \bar r$.

%   The bound \eqref{eq:above2} must hold for any $r$. The expression $|r-R_f|$ will reach
%   its largest value at $r=-\bar r$, since $R_f$ is assumed to be non-negative.

%   Finally we consider the case where, without loss of generality, $c(p_2,r)=0$. Then, if
%   $c$ had not been defined using $\lfloor\cdot\rfloor$, then we would have
%   \begin{align}
%     |\floor*{c(p_1,r)} - \floor*{c(p_2,r)}| &\leq |c(p_1,r) - c(p_2,r)|\\
%     &\leq \sigma|p_1-p_2|.\qedhere
%   \end{align}
% \end{proof}

% \begin{rem}
%   Our proposed algorithm has the form \eqref{eq:above3}, and so has algorithmic stability
%   bounded by
%   \begin{equation}
%     \alpha_n \leq \frac{(\bar r+R_f)^2X^2_{\max}}{2\lambda n}
%   \end{equation}
%   with linear utility and
%   \begin{equation}
%     \alpha_n \leq \frac{\exp(2\mu\bar r)X^2_{\max}}{2\lambda n}
%   \end{equation}
%   in the case of exponential utility.
% \end{rem}

% \begin{rem}
%   The maximum loss we can suffer over a single data point happens when $r_i=-\bar r$ and
%   $p=1$, ie.
%   \begin{equation}
%     c(1,-\bar r) = U(R_f) - U(\bar r).
%   \end{equation}
%   We shall call this quantity $\gamma$.
% \end{rem}

% \begin{rem}
%   Our algorithm has a generalization bound of
%   \begin{equation}
%     |R_{\text{true}}(A,S_n) - \hat R(A,S_n)| \leq 2\alpha_n + (4n\alpha_n + \gamma) \sqrt{\frac{\log(2/\delta)}{2n}}.
%   \end{equation}
% \end{rem}


\section{Multi-asset Portfolio}

We now consider a multi-asset portfolio, made of $m$ risky assets and a risk-free
asset. Each of theses risky assets have information vector $x_{st}$, where
$s\in\{1,\ldots,m\}$ and $t\in\{1,\ldots,n\}$. Therefore, we suppose having access to a
sample dataset $S_n = \{X_1,\ldots,X_n\}$ where $X_i\in\real^{m\times p}$.

There are two ways to approach the multi-asset scenario. 


\subsection{First approach}

On one hand, we can define a single decision vector $q$ such that the return on a single
holdinq period would be defined by
\begin{equation}
  r^{T}Xq + (1 - 1^{T}Xq)R_f,
\end{equation}
where $r\in\real^{m}$ is the return vector of the $m$ stocks and $1^T$ is a contant vector
of ones in $\real^m$ whose role is simply to sum over the components of $Xq$, ie. sum over
the risky allocations of the portfolio. However, this method has the disadvantage that the
decision vector is applied for each stock in the same way, and so all their information
vectors are ultimately `averaged' over. Therefore, if some asset is more sensitive to an
information component than other assets, this knowledge might be lost if using this
method. 

Nevertheless, we can again define two different cost functions, which our optimal decision
vector would minimize when applied to our sample dataset $S_n$. Again, the cost can be
simply defined as
\begin{equation}
  c(p,r) = -U(r^{T}p + (1 - 1^{T}p)R_f).
\end{equation}
As discussed previously, this definition might have the disadvantage of providing an
unconstrained optimization problem when determining the optimal decision vector.

We are not limited to a single cost definition, and in fact, the multi-asset scenario
provides many legitimate cost definitions. Here the most `aggressive' one:
\begin{equation}
  c(p,r) =
  \begin{cases}
    \floor{U(\max r) - U(r^{T}p + (1-1^{T}p)R_f)} & \text{if } \max r>R_f\\
    \floor{U(R_f) - U(r^{T}p + (1-1^{T}p)R_f)} &\text{if } \max r\leq R_f.
  \end{cases}  
\end{equation}
This means that we expect (or conversely, that we suffer a lesser loss) when the total
return of our portfolio is near the best return achieved by our considered stocks. Instead
of $\max r$, we also could have chosen the average returns $\bar r$ during the period as
the target that we wish to achieve (provided that the average is superior to the risk-free
return). We could in fact chose any function mapping from a vector of returns $r$ to a
scalar as our global return objective.

In any case, the algorithm determining the decision vector $q$ would once be defined as
previously, ie. as \eqref{algo}.


\subsection{Second approach}

Under this second approach, instead of averaging over all information vector at the risk
of losing asset-specific information, we now use a decision matrix $Q$ of size $p\times
m$, whose $m$ columns are actually trained independently one to each other so that each
asset reacts differently from the rest. 

The allocation of each vector would then be $\diag(XQ)$, ie. the diagonal elements of the
$m\times{}m$ matrix $XQ$. The one-period return is therefore
\begin{equation}
  r^{T}\diag(XQ) + (1 - 1^{T}\diag(XQ))R_f.
\end{equation}

This method still has a disadvantage though, in that it won't consider the eventual
influence of information $x_j$ of asset $j$ to asset $j$, ie. each stock is trained
independantly one to each other.

\subsection{Third Approach}

Finally, we introduce a third approach with the objective of using all available data of
the market, available through $X\in\real^{m\times sp}$. However, we must be clear about
what information $X$ carries with it; its information is only bounded to different
assets, and therefore does not include `global' information with it.

Following a simple idea introduced by \cite{wsj}, we can add an unknown linear
transformation $W$ to $X$ so that $q$ can benefit from the whole information matrix, and
not only from the average of its columns. The total return using a transformation $W$ and
decision vector $q$ would therefore be expressed as
\begin{equation}
  r^{T}XWq + (1 - 1^{T}XWq)R_f.
\end{equation}

\textbf{Add something perhaps on how he can cramp into the model some paarameters so that
  only a handful assets are being chosen (perhaps L1 reg. or something like that).  Also
  maybe we could add another complexity where we would like to keep stocks we already
  have, perhaps using a utility telling how much we want to discourage the new daily
  assets. That sort of things.}

\textbf{Something else that was so far overlooked is the fact that the sum of all
  allocation components need not sum up to 1. Again, a regularization with a plateau shape
  form could perhaps translate what we need.}
 

\begin{thebibliography}{99}

\bibitem{rudin2015}
  Cynthia Rudin and Gah-Yi Vahn. \textit{The Big Data Newsvendor: Pratical Insights from
    Machine Learning}, Operations Research, 2015.

\bibitem{bousquet2002}
  Olivier Bousquet and André Elisseeff. \textit{Stability and Generalization}, Journal of
  Machine Learning Research, 2002.

\bibitem{rockafellar}
  Rockafellar, R.~T. \emph{Convex Analysis}, Princeton University Press, 1970.

\bibitem{wsj} Ming Fai Wong et al. \emph{Stock Market Prediction from WSJ: Text Mining via
    Sparse Matrix Factorization.} ICDM 2014. 

\end{thebibliography}
\end{document}
