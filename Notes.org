#+TITLE: Notes
#+AUTHOR: Thierry BM
#+STARTUP: entitiespretty

* *Le 8 juin*

_Quelques définitions (dans le cas /newsvendor and portfolio/)_

Le vrai risque:

			R_{true}(q) = E_{D(x)}[C(q; D(x))]
				= E_{x}[E_{D(x)}[C(q; D(x))|x]]

Le risque empirique:

			  ^R(q;S_{n}) = 1/n \sum_{i}C(q, S_n^i)
				   = 1/n \sum_{i}C(q, d_i(x_i))

"Since we desire the true risk to be low, a combination of low empirical risk and
sufficient stability ensures this."


Let X:R^p be the information distribution, providing objects of the R^p form, and let R(x):R
be the (real) distribution returns, and let D = R\times{}X the /information space/. 

_Learning Algorith._
A /learning alogrithm/ is a function whose argument is a dataset drawn from D^n, ie. with n
rows, mapping into the space of functions mapping from X to a portfolio space (to be
defined later) P. We shall denote this space of functions as X^P.

_Loss of a decision vector q._
The /loss/ l of a decision rule q \in Q \subset{} X^P with respect to a sample d=(x,r) \in{} D is defined as

				  l(q,d) = c(q(x),r(x))

for some cost function. 


Now how should this loss function be defined? On one hand we have the actual return of the
chosen stock. The real question here is when would the loss be zero. We always gain more
utility from higher return, and so if the chosen q gives us huge gains, then we cannot
claim that there's a single return at which the loss is completely absent. Our loss
function would therefore take the form of a decreasing exponential function exp(-\mu{}x).

But if we had such a loss function, we would then be out of line with a two-pieces linear
utility function. A log utility is of no use too, since its domain is only on R_{++}_{}. 

[[./Mai2015/FigExpUtility2.png]]

But -exp(-\mu{}x) could be a good utility function, that can besides be scaled and moved
around using a parameter \mu as an increasing rate. However we lose the insight developed
previously with the Newspaper article. 

The loss exp(-\mu{}x) is then perfectly in line with the utility and provide a reasonable
insight since the loss occured for higher return rates is much smaller than the loss
incured when dealing with higher return rates. 

We're also inline with the loss function of the newsvendor, since the loss we're trying to
minimize is now the same as the utility we're trying to maximize (modulo a minus sign).

In the newsvendor case, the loss the hypothesis q incurs on a random variate d=(x,r) drawn
from D, was defined as

				    \ell(q,d) = c(q(x),d)

where c was the newsvendors cost incurred from a demand d and an ordered quantity q(x). 

In our case, we again have not a situation where the loss is null, essentially because
we're in fact /not/ trying to predict the actual return rate, we instead try to form a good
portfolio from which we want to derive utility. The other problem, as mentioned
previously, is also that our utility has no supremum, ie. is not bounded above. In
pratical terms, this means that there's no single best decision that could have been made
had we known the return rate previously: if the rate was to be positive, then would have
massively borrowed to leverage the positive rate. On the other side, if the rate was
negative, then the reverse situation where we could have chosen between a mass short sale
or risk-free lending would have appropriate.

And in this sense, would there be no way to add a regularization term, ie. with which we
would discourage massive investments?

Here's a possible method to define \ell, but we first have to assume that ||q(x)||_2^2 \leq 1,
ie. the investment in the risky asset (under the two-assets portfolio hypothesis) is
bounded by 100%, in financial terms, we cannot borrow money at R_f to invest in the risky
asset. 

If r, ie. the return of the risky asset is above R_f, then we'll have wished we had
invested all our wealth in it, and thus the loss will be 

				  U(1,0) - U(q^{T}x, 1-q^{T}x)

if on the other hand the stock yields a return below R_f, then the reference will be the
utility derived from a perfectly safe portfolio, so that the loss becomes

				  U(0,1) - U(q^{T}x, 1-q^{T}x)

In either case, the loss is always positive (or at most zero).

*Note.* In the above expressions, U(x,y) represents the utility of a portfolio for which a
 proportion x is invested in the risky asset and y in the risk free asset.

According to Bousquet, an algorithm has \beta uniform stability with respect to the loss
function l if for all dataset of m rows, we have the bound

		      `||\ell(q(S_m,d) - \ell(q(S'_m,d))||_{\infty} \leq \beta_m

where q' is the hypothesis formed when removing a single row from S_m, the dataset (see
Bousquet p. 504 for total formalism). 

*Def.* An algorithm is uniformly stable if \beta_{m }\leq O(1/n).

*Def.* The /generalization error/ or the /risk/ depends on the training set S and the algorithm
 A_S in the following way:

				  R(A_S,S) = E_{d}[\ell(A_s,d)]

*Def.* The /empirical error/ is the average of the loss over the training set S of m
elements:

			       R_{emp}(A_S,S) = 1/m \sum_i \ell(A_s, d)



* *Le 9 juin*

We still wish to apply theoretical bounds upon the `loss' we can incur using our
algorithm. We use the notion of uniform stability, as developed by Bousquet and Elisseef
in their seminal work. 

*Def (Uniform stability).* An algorithm A has uniform stability \beta with loss \ell if, for any
 dataset S of m rows, ie. \forall S \in D^m, and any removed row i, then for d=(x,r) \sim{} D,

		    `   ||\ell(A_S(x), r) - \ell(A_{S\i}(x), r)||_{\infty} \leq \beta

ie.,

	            B_m = sup_{d \in D} |\ell(A_S(x), r) - \ell(A_{S\i}(x), r)| \leq \beta

For notation purposes, the left value, depending solely on the size m of S, will be
henceforth noted B_m or simply B.

Now for the hard part of giving a value to \beta. The problem with the current value of \ell is
how it has not a constant mapping, and will change its underlying application wether r is
above or below r_c (which could be R_f). 

Below are the two forms the loss function, depending on the portfolio composition: p=0 is
a perfectly safe portfolio, p=1 is a perfectly risky portfolio. They were plotted using
the exponential utility. 

[[./Mai2015/expULossAboveZero.png]]

[[./Mai2015/expULossBelowZero.png]]

We'll most probably need to bound the return drawn from the returns distribution R in the
interval [-\rho, \rho]. We can then add probalistic bounds upon it as described [[https://en.wikipedia.org/wiki/Stability_(learning_theory)#Uniform_Stability][in this
article]]. We also note that the loss function \ell thus defined is continuous with respect to
r. 

Let's make our ideas clearer. We have the following identities:

			c(p,r) = U(r) - U(pr + (1-p)r_c) if r > r_c
			c(p,r) = U(0) - U(pr + (1-p)r_c) if r \leq r_c
				    p = q_S^{T}x = q(S)^{T}x

Actually, this `multi-defined' function is in fact not that remote from the stability
criterion exhibited in the newsvendor case, where we have operators min and max operators
(\vee and \wedge{}) on the slopes of the cost function.

Let us first consider a fixed dataset S from which a decision vector q_S is algorthmically
defined, and let us apply the definition of the uniform stability. Then, no matter the
value of r, we're left with the following expression for B:

		  B = sup_{d \in D} |U(pr + (1-p)r_c) - U(p'r + (1-p')r_c)|

where 

				   p' = q(S^{\i})^{T}x

is the `less-informed' decision.

Now we can again apply the Lipschitz property of continuous functions stating that,
provided that dom f = S convex, then

`			     |f(x) - f(y)| \leq \alpha |x-y|

where

			       \alpha = sup_{x \in S} |f'(x)|

If the utility is linear, then \alpha = \beta, the slope of the utility left of r_c. If however we
consider an exponential utility, then the maximum value of the derivative will only be
reached at the edge of the considered interval, and so \alpha = \mu{} exp(\rho), which can be quite
high (more on that later...)

Either way, B is now bounded:

			   B \leq sup_{d \in D} \alpha |(p-p')(r-r_c)|
			     = \alpha sup |r-r_{c}| sup_{d \in D} |p - p'|

In the above expression, sup |r-r_{c}| will be \rho + r_c, since we asume that r_c > 0. We shall
call this quantity \gamma so that

				   B \leq \alpha{} \gamma sup |p - p'|

C'est là qu'on est rendu...


* Le 10 juin

We've been trying for a few days to establish a bound on the uniform stability of the
linear algorithm when dealing with a concave utility, and to do so we must dive into how
the algorithm operates.

We have the following equalities:

			      q_S = argmax_{q} Û(q,S) - \lambda||q||_2^2
			  q' = q_{S\i} = argmax_{q} Û(q,S^{\i}) - \lambda||q||_2^2

By the triangle equality we also have

'		      |p - p'| = |(q - q')^{T}x| \leq \sum_i |x_{i}| |q_i - q_{i}'|

					  * * *

Let's instead follow Theorem 22 from Bousquet. We first want to show that \ell as defined
previously is \sigma-admissible.

				  \ell(q,(x,r)) = c(q^{T}x,r)

(Bousquet, Definition 19, p. 512)
*Def. (\sigma-admissibility).* A loss function \ell is \sigma-admissible if the associated cost function
 c is convex with respect to its first argument and the following condition holds for any
 p_1, p_2 and r:

`			   |c(p_1,r) - c(p_2,r)| \leq \sigma |p_1 - p_{2}|

We've shown yesterday that the left term reduces to

`				  |(p_1 - p_2)(r - r_c)|

The largest value |r - r_{c}| can reach is \rho+r_c, and so \sigma = \rho+r_c (previously declared as \gamma).


* Le 15 juin

