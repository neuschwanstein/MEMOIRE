#+TITLE: Notes
#+AUTHOR: Thierry BM
#+STARTUP: entitiespretty

Plutôt que d'avoir une fonction d'utilité qui n'est de toute facon pas convexe, on peut
plutot tracer une fonction d'utilité qui vise un certain rendement. Ainsi, si on appelle
ce rendement r_c, l'utilité croît très rapidement lorsqu'elle se dirige à partir de la
gauche, alors qu'au contraire, lorsqu'elle s'en éloigne, ie. lorsqu'on observe des
rendements /supérieurs/ au rendement critique r_c, l'utilité décroit, mais beaucoup moins
rapidement.

On a ainsi un objectif qui est /convexe/, et on a un problème qui somme toute est plus ciblé
autour d'un objectif précis. Si besoin est, on peut même raffiner l'utilité pour bien
définir comment on souhaite que la performance soit pénalisée ou non. 

On ajoute ensuite de la sélection de modèle à notre guise.

Maintenant qu'on obtient un /q/, comment construire alors notre portefeuille? Pour chaque
stock, on obtient une proportion à investir, disons p_s. Disons qu'on désire investir dans
/n/ actifs différents, question de diversification, parmi /m/ actifs.

On peut ordonner les actifs par la valeur de q.x_s, car une valeur plus élevée indique
qu'on a davantage confiance dans ce stock pour fournir un rendement proche de notre
rendement idéal r_c.

On aura alors n proportions différentes (comprises pas tout à fait encore malheureusement)
entre 0 et 1. Supposons qu'on ait une suite {p_1,p_2,...,p_n} de proportions. On veut
construire un portefeuille avec tous ces actifs. Le portefeuille sera alors constitué
d'une proportion p_1 d'actifs risqués, et de l'actif sans risque. 

L'actif 2 sera alors constiué dans une proportion p_2 p_1^2, l'actif 3 dans une proportion
p_{3}p_{2}p_{1}^2. La règle de récurrence sera alors

				      p'_{i+1} = p_{i+1 }p_i

et 

				  p'_1 = 1 - \sum_{i\ge 2}_{} p'_i

La valeur de m peut à nouveau être déterminée par sélection de modèle. 


					  * * *

*Le 19 avril 2015*

On travaille une utilité de la forme 

			    U(p) = \alpha_1(r_c - p)^{ +} + \alpha_2(p - r_c)^{ +}

où r_c est le rendement souhaité. p est le rendement obtenu. On souhaite maximiser cette
utilité. 

Chaque stock s possède un vecteur d'informations x_s déterminé à tous les jours. Notre
portefeuille est constitué de m actifs risqués et d'un actif sans risque. Donné q, le
rendement du portefeuille sur une période d'une journée est donné par

		       p^m(q) = p_{1}r_1 + p_{2}r_2 + \cdots + p_{m}r_m + (1 - \sum{}p_i) R_f

On détermine q avec le programme d'optimisation suivant:

				max_q \sum_{s}\sum_{t} U(p_{st}(q))

Où ici 

			    p_{st}(q) = r_{st} q^{T}x_{st} + R_f(1 - q^{T}x_{st})

On cherche donc à déterminer le vecteur q qui permettra de maximiser l'utilité /sur tous/
/les actifs, sur toutes les périodes/, autrement dit, un tel q permettrait de déterminer, en
moyenne l'allocation qui permettrait de se rapprocher d'un portefeuille de rendement r_c.

A x_s on entend donc faire correspondre un /rendement/ r_s à l'aide d'une fonction q(x_s) =
r_s. En somme, on considère que le rendement d'un certain actif ne serait pas uniquement
déterminé de facon intrinsèque mais serait alors déterminé à partir du vecteur
d'information x_s.

					  * * *

*Le 20 avril 2015*

Revenons sur la nouvelle interprétation de q. Si par exemple on constitue de une base de
données constituée d'un seul actif, alors q fournira q.x_s fournira la proportion à
investir si on vise un rendement r_c, donc

				r q^{T}x_s + R_f(1 - q^{T}x_s) = r_c

d'où on tire

			       q^{T}x_s = (r_c - R_f) / (r - R_f)

dont on peut se servir pour mesurer à quel point notre algorithme est efficace, ie. en
comparant les résultats empiriques avec ceux prédits par la théorie. 

Reste encore l'épineuse question de la normalisation, car pour certains attributs, chacun
peut possiblement se situer à des niveaux très différents. Aussi c'est pourquoi une
normalisation individuelle (par exemple recentré à la moyenne et réduit de \rho écart types).

Par contre, on fait implicitementl'hypothèse que /l'amplitude relative/ des valeurs n'est
pas importante. Peut être y aurait il moyen de rajouter cette information dans x_s, sur une
colonne représentant pour chaque actif s'\neq{}s, la fraction d'amplitude. A voir. 

Une fois que nos données sont recentrées, on aura alors dans une proportion déterminée (_à
vérifier_) des points tels que |x_{s}|\leq1. Supposons qu'on préfère permettre une allocation
de portefeuille risquée comprise dans un intervalle [-\alpha, 1+\alpha], autrement dit on permet
dans une certaine mesure la vente à découvert et l'emprunt à R_f pour obtenir davantage
d'exposition au marché. 

Si dans notre programme d'optimisation on emploie

				      q' = (1 + q)/2

					  * * *

La forme de la fonction d'utilité devient alors

		      U(p) = -\beta_1 Max(r_c - p, 0) - \beta_2 Max(p - r_c, 0)

\beta_1 contrôle la pente de l'utilité pour des rendements inférieurs à r_c, \beta_2 contrôle la
pente pour des rendements supérieurs à r_c. On aura donc typiquement 

					 \beta_1 < \beta_2,

puisque des rendements supérieurs sont moins susceptibles d'affecter l'utilité.

Si p est fonction de q, par la fameuse relation

			      p(q) = r_s q^{T}x_s + R_f (1 - q^{T}x_s)

alors on aura, au sens général, 

	    U(q) = -\beta_1 (r_c - R_f + q^{T}x_s(R_f - r_s))^{+} - \beta_2 (R_f - r_c + q^{T}x_s(r_s - R_f))^{ +}

Si on lance un programme d'optimisation convexe de la forme

				   max_q \sum_{s}\sum_{t} U(q)
				    sc. |q| \leq 1

Et qu'on suppose les vecteurs d'information x_s normalisés, ie. |x_{s}| \leq 1, alors la
proportion comprise entre -1 et 1 (dans la plupart des cas). On voudrait que cette
proportion soit comprise entre [-\alpha, 1+\alpha].

Par exemple, si on pose \alpha=0, alors la transformation nécessaire pour obtenir un nouveau q
serait la suivante:

				      q' = (1 + q)/2

et ainsi on aurait la juste proportion d'investissement du portefeuille. 


					  * * *

*Le 21 avril*

Choses restant à faire:

  - Donner une période de dates lors de l'appel à x.
  - Rajouter un attribut pour représenter l'éloignement d'une certaine date.
  - +Rajouter le prix moyen des n derniers jours+
  - Aller chercher de l'information sur le CA et sur le PDG. Par exemple, le genre et
    l'âge du CEO (qu'on peut assumer être le premier dans la liste), et l'âge moyen et le
    genre moyen des autres membres /clés/ (au sens de Yahoo).


					  * * *

*Le 23 avril*

La question de la normalisation, toujours aussi épineuse. Voyons voir nos contraintes.

On veut que d'une part les attributs soient environ à la même échelle, pour que la
régularisation ait un sens. En effet, si par exemple on compare le volume quotidien de
vente, typiquement de l'ordre de 10^{6}, avec celui d'une volatilité sur 30 jours, de l'ordre
de 10^-1, naturellement l'ordre de grandeur des composantes de q ne sera pas semblable et
la normalisation sera alors biaisée.

Pour s'assurer qu'on travaille sur un ordre de grandeur commun, on pourrait alors préférer
recentrer tous les vecteurs d'information autour de la moyenne, puis ensuite réchelonner
selon la distance entre les valeurs extrêmes, de facon à avoir toutes les composantes du
nouveau vecteur réchelonné x' compris dans une boite de volume 1, ie.

				       ~|x|_{1} \leq 1

En pratique, on permet donc au vecteur d'information d'avoir une norme euclidienne L_2
supérieure à 1, mais toutefois assez proche.

Ceci permet également de construire une matrice sur laquelle on peut appliquer nos
nouveaux vecteurs d'information, afin d'en créer un vecteur de décision q.

Mais au fait de combien doit on les recentrer ces vecteurs d'informations? Car prenons par
exemple la colonne d'information pour un certain jour de la semaine. Ses valeurs
oscilleront entre 0 et 1, toutefois elles ne seront pas distribués uniformément puisque la
fonction donnant la valeur est une exponentielle. Donc sa moyenne ne tombera pas à 0.5
comme on aurait pu l'espérer. Faudrait il donc dans ce cas particulier les recentrer à
0.5?

A réfléchir...

Bref, de toute facon nos mesures sont influencées par la présence du terme de biais,
présentement évalué à 1, mais qu'on aurait peut être avantage à changer pour une valeur
qui serait réchelonnée selon p, le nombre d'attributs.


					  * * *

*Le 25 avril*

  - Problème avec les jours. Ils n'atteignent pas 1!
  - Pourtant les semaines semblent bien fonctionner!

Ne pas oublier, si 

				     M \in R^{m\times{}n}

alors M est une matrice de m rangées et de n colonnes.

J'ai changé l'objectif pour y inclure un terme favorisant une norme /élevée/ pour
q. Soudainement on a un portefeuille qui se met à bouger davantage, ce qui est assez
encourageant. 

Supposons un taux annuel r_a. Alors le taux quotidien r_q sera tel que

				    r_q = log(1+r_q)/252

De la même facon, donné un taux quotidien r_q, le taux annuel correspondant sera 

				   r_a = exp(252 r_q) - 1
