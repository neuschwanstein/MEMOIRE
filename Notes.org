#+TITLE: Notes
#+AUTHOR: Thierry BM
#+STARTUP: entitiespretty

* *Le 8 juin*

_Quelques définitions (dans le cas /newsvendor and portfolio/)_

Le vrai risque:

			R_{true}(q) = E_{D(x)}[C(q; D(x))]
				= E_{x}[E_{D(x)}[C(q; D(x))|x]]

Le risque empirique:

			  ^R(q;S_{n}) = 1/n \sum_{i}C(q, S_n^i)
				   = 1/n \sum_{i}C(q, d_i(x_i))

"Since we desire the true risk to be low, a combination of low empirical risk and
sufficient stability ensures this."


Let X:R^p be the information distribution, providing objects of the R^p form, and let R(x):R
be the (real) distribution returns, and let D = R\times{}X the /information space/. 

_Learning Algorithm._
A /learning alogrithm/ is a function whose argument is a dataset drawn from D^n, ie. with n
rows, mapping into the space of functions mapping from X to a portfolio space (to be
defined later) P. We shall denote this space of functions as X^P.

_Loss of a decision vector q._
The /loss/ l of a decision rule q \in Q \subset{} X^P with respect to a sample d=(x,r) \in{} D is defined as

				  l(q,d) = c(q(x),r(x))

for some cost function. 


Now how should this loss function be defined? On one hand we have the actual return of the
chosen stock. The real question here is when would the loss be zero. We always gain more
utility from higher return, and so if the chosen q gives us huge gains, then we cannot
claim that there's a single return at which the loss is completely absent. Our loss
function would therefore take the form of a decreasing exponential function exp(-\mu{}x).

But if we had such a loss function, we would then be out of line with a two-pieces linear
utility function. A log utility is of no use too, since its domain is only on R_{++}_{}. 

[[./Mai2015/FigExpUtility2.png]]

But -exp(-\mu{}x) could be a good utility function, that can besides be scaled and moved
around using a parameter \mu as an increasing rate. However we lose the insight developed
previously with the Newspaper article. 

The loss exp(-\mu{}x) is then perfectly in line with the utility and provide a reasonable
insight since the loss occured for higher return rates is much smaller than the loss
incured when dealing with higher return rates. 

We're also inline with the loss function of the newsvendor, since the loss we're trying to
minimize is now the same as the utility we're trying to maximize (modulo a minus sign).

In the newsvendor case, the loss the hypothesis q incurs on a random variate d=(x,r) drawn
from D, was defined as

				    \ell(q,d) = c(q(x),d)

where c was the newsvendors cost incurred from a demand d and an ordered quantity q(x). 

In our case, we again have not a situation where the loss is null, essentially because
we're in fact /not/ trying to predict the actual return rate, we instead try to form a good
portfolio from which we want to derive utility. The other problem, as mentioned
previously, is also that our utility has no supremum, ie. is not bounded above. In
pratical terms, this means that there's no single best decision that could have been made
had we known the return rate previously: if the rate was to be positive, then would have
massively borrowed to leverage the positive rate. On the other side, if the rate was
negative, then the reverse situation where we could have chosen between a mass short sale
or risk-free lending would have appropriate.

And in this sense, would there be no way to add a regularization term, ie. with which we
would discourage massive investments?

Here's a possible method to define \ell, but we first have to assume that ||q(x)||_2^2 \leq 1,
ie. the investment in the risky asset (under the two-assets portfolio hypothesis) is
bounded by 100%, in financial terms, we cannot borrow money at R_f to invest in the risky
asset. 

If r, ie. the return of the risky asset is above R_f, then we'll have wished we had
invested all our wealth in it, and thus the loss will be 

				  U(1,0) - U(q^{T}x, 1-q^{T}x)

if on the other hand the stock yields a return below R_f, then the reference will be the
utility derived from a perfectly safe portfolio, so that the loss becomes

				  U(0,1) - U(q^{T}x, 1-q^{T}x)

In either case, the loss is always positive (or at most zero).

*Note.* In the above expressions, U(x,y) represents the utility of a portfolio for which a
 proportion x is invested in the risky asset and y in the risk free asset.

According to Bousquet, an algorithm has \beta uniform stability with respect to the loss
function l if for all dataset of m rows, we have the bound

		      `||\ell(q(S_m,d) - \ell(q(S'_m,d))||_{\infty} \leq \beta_m

where q' is the hypothesis formed when removing a single row from S_m, the dataset (see
Bousquet p. 504 for total formalism). 

*Def.* An algorithm is uniformly stable if \beta_{m }\leq O(1/n).

*Def.* The /generalization error/ or the /risk/ depends on the training set S and the algorithm
 A_S in the following way:

				  R(A_S,S) = E_{d}[\ell(A_s,d)]

*Def.* The /empirical error/ is the average of the loss over the training set S of m
elements:

			       R_{emp}(A_S,S) = 1/m \sum_i \ell(A_s, d)



* *Le 9 juin*

We still wish to apply theoretical bounds upon the `loss' we can incur using our
algorithm. We use the notion of uniform stability, as developed by Bousquet and Elisseef
in their seminal work. 

<<uniformStabilityDefinition>>
*Def (Uniform stability).* An algorithm A has uniform stability \beta with loss \ell if, for any
 dataset S of m rows, ie. \forall S \in D^m, and any removed row i, then for d=(x,r) \sim{} D,

		    `   ||\ell(A_S(x), r) - \ell(A_{S\i}(x), r)||_{\infty} \leq \beta

ie.,

	            B_m = sup_{d \in D} |\ell(A_S(x), r) - \ell(A_{S\i}(x), r)| \leq \beta

For notation purposes, the left value, depending solely on the size m of S, will be
henceforth noted B_m or simply B.

Now for the hard part of giving a value to \beta. The problem with the current value of \ell is
how it has not a constant mapping, and will change its underlying application wether r is
above or below r_c (which could be R_f). 

Below are the two forms the loss function, depending on the portfolio composition: p=0 is
a perfectly safe portfolio, p=1 is a perfectly risky portfolio. They were plotted using
the exponential utility. 

[[./Mai2015/expULossAboveZero.png]]

[[./Mai2015/expULossBelowZero.png]]

We'll most probably need to bound the return drawn from the returns distribution R in the
interval [-\rho, \rho]. We can then add probalistic bounds upon it as described [[https://en.wikipedia.org/wiki/Stability_(learning_theory)#Uniform_Stability][in this
article]]. We also note that the loss function \ell thus defined is continuous with respect to
r. 

Let's make our ideas clearer. We have the following identities:
<<definitionCost>>

			c(p,r) = U(r) - U(pr + (1-p)R_f) if r > R_f
			c(p,r) = U(R_f) - U(pr + (1-p)R_f) if r \leq R_f
				    p = q_S^{T}x = q(S)^{T}x

Actually, this `multi-defined' function is in fact not that remote from the stability
criterion exhibited in the newsvendor case, where we have operators min and max operators
(\vee and \wedge{}) on the slopes of the cost function.

Let us first consider a fixed dataset S from which a decision vector q_S is algorithmically
defined, and let us apply the definition of the uniform stability. Then, no matter the
value of r, we're left with the following expression for B:

		  B = sup_{d \in D} |U(pr + (1-p)r_c) - U(p'r + (1-p')r_c)|

where 

				   p' = q(S^{\i})^{T}x

is the `less-informed' decision.

Now we can again apply the Lipschitz property of continuous functions stating that,
provided that dom f = S convex, then

`			     |f(x) - f(y)| \leq \alpha |x-y|

where

			       \alpha = sup_{x \in S} |f'(x)|

If the utility is linear, then \alpha = \beta, the slope of the utility left of r_c. If however we
consider an exponential utility, then the maximum value of the derivative will only be
reached at the edge of the considered interval, and so \alpha = \mu{} exp(\rho), which can be quite
high (more on that later...)

Either way, B is now bounded:

			   B \leq sup_{d \in D} \alpha |(p-p')(r-r_c)|
			     = \alpha sup |r-r_{c}| sup_{d \in D} |p - p'|

In the above expression, sup |r-r_{c}| will be \rho + r_c, since we asume that r_c > 0. We shall
call this quantity \gamma so that

				   B \leq \alpha{} \gamma sup |p - p'|

C'est là qu'on est rendu...


* Le 10 juin

We've been trying for a few days to establish a bound on the uniform stability of the
linear algorithm when dealing with a concave utility, and to do so we must dive into how
the algorithm operates.

We have the following equalities:

			      q_S = argmax_{q} Û(q,S) - \lambda||q||_2^2
			  q' = q_{S\i} = argmax_{q} Û(q,S^{\i}) - \lambda||q||_2^2

By the triangle equality we also have

'		      |p - p'| = |(q - q')^{T}x| \leq \sum_i |x_{i}| |q_i - q_{i}'|

					  * * *

Let's instead follow Theorem 22 from Bousquet. We first want to show that \ell as defined
previously is \sigma-admissible.
<<lossDefinition>>
				  \ell(q,(x,r)) = c(q^{T}x,r)

(Bousquet, Definition 19, p. 512)
<<sigmaAdmissibilityDefinition>>
*Def. (\sigma-admissibility).* A loss function \ell is \sigma-admissible if the associated cost function
 c is convex with respect to its first argument and the following condition holds for any
 p_1, p_2 and r:

`			   |c(p_1,r) - c(p_2,r)| \leq \sigma |p_1 - p_{2}|

We've shown yesterday that the left term reduces to

`				  |(p_1 - p_2)(r - r_c)|

The largest value |r - r_{c}| can reach is \rho+r_c, and so \sigma = \rho+r_c (previously declared as \gamma).


* Le 15 juin

First, previously undefined formally:

<<linearUtilityDefinition>>
_Def. (Linear Utility)_ The linear utility is defined as

				  U(r) = r + min(0, \beta{}r)

where 0 < \beta < 1. We simplify r_c = 0.

<<expUtilityDefinition>>
_Def. (Exponential Utility)_ The exponential utility with parameter \mu is defined as

				    U(r) = -exp(-\mu r)

where \mu > 0. There's no critical return here. 

We also note in the above expression that [[definitionCost][c]] is indeed convex under its first argument, as
long as 0 \leq p \leq 1.

<<sigmaAdmissibilityTheorem>>
_Thm._ The [[lossDefinition][loss function]] is [[sigmaAdmissibilityDefinition][\sigma-admissible]] with \sigma = \rho+R_f in the linear case and
\sigma = (\rho+R_{f}) exp(\mu \rho) in the exponential case.

_Proof._ The expression

				   `|c(p_1,r) - c(p_2,r)|

reduces to

			 `|U(p_{1}r + (1-p_{1})R_f) - U(p_{2}r + (1-p_2)R_f_{}|.

Now because U is Lipschitz continuous, then the above expression is bounded by

		 \sigma |p_{1}r + (1-p_{1})R_f - (p_{2}r + (1-p_2)R_{f}| = \alpha |p_1 - p_{2}||r-R_{f}|

where

			      \alpha = max_{x \in [-\rho,\rho]} |U'(x)|.

Now we've considered two utility forms. In the [[linearUtilityDefinition][linear case]] the derivative is constant (set
to 1) because the derived utility at the left of r_c has always slope 1, and so \alpha=1. If
[[exoUtilityDefinition][utility is exponential]], then \alpha = exp(\mu \rho). 

Now the \sigma bound must hold for all r. The expression |r-R_{f}| will reach its largest value at
r=-\rho since R_{f} is asumed to be non-negative. \Diamond

Just like in the newsvendor case, we'll assume that feature vectors must lie in a ball of
radius X^2_{max}.

<<BousquetTheorem7>>
Let F be a reproducing kernel Hilbert space with kernel k such that \forall x \in X, k(x,x) \leq \kappa^2
< \infty. Let \ell be [[sigmaAdmissibilityDefinition][\sigma-admissible]] with respect to F. The learning algorithm A defined by

		A_{S} = argmin_{g \in F} 1/n \sum_i^n \ell(g,d_i) + \lambda ||g||^2_k

has [[uniformStabilityDefinition][uniform stability]] \alpha_n wrt \ell with

			  \alpha_n \leq \sigma^{2 }\kappa^2 / 2\lambda{}n.

<<algorithm>>
The decision algorithm of our model produced by a dataset S_n = {(x,r)_i} is defined to be 

	     q^\star = argmin_{q \in R^p} 1/n \sum_i^n c(q^{T}x_i,r_i) + \lambda||q||^2_2

The investment decision following information vector x will therefore be p = q^\star^{T}x,
where p is the proportion to be invested in the risky asset.

<<stabilityTheorem>>
Using The [[uniformStabilityDefinition][stability]] \alpha_n of our proposed [[algorithm]] is bounded by the following:

			       \alpha_n \leq (\rho + R_f)^2 X^2_max / 2\lambda{}n

in the case of a linear utility and by 

			      \alpha_n \leq exp(2\mu \rho) X^2_max / 2\lambda{}n.

These results follow from the [[sigmaAdmissibilityTheorem][\sigma-admissibility theorem]] of our [[lossDefinition][loss function]] and
[[BousquetTheorem7][Bousquet's Theorem]].

<<trueRiskDefinition>>
The true risk with respect to algorithm A and learning set S_n is defined as

			      R_{true}(A,S_n) = E_{d}[\ell(A_S, d)]

that is, in plain words, the expected loss we'll have when applying our algorithm in the
wild, ie. out of sample.

<<empiricalRiskDefinition>>
The empirical risk with respect to algorithm A and learning set S_n is defined to be 

			     ^R(A,S_n) = 1/n \sum_i^n \ell(A_S, z_i)

that is, in plain words, the average risk our model has produced over all training
points. 

<<maxCostProposition>>
Using the aforementioned algorithm, the maximum loss we can incur is when p=1 with
r=-\rho. In such a case, 

				 c(1,-\rho) = U(R_f) - U(\rho).

We shall call this quantity \gamma.

<<RudinLemma2>>
Let A be an algorithm with uniform stability \alpha_n wrt a loss function \ell such that 0 \leq
\ell(A_S,d) \leq M, for all d = (x,r) \sim D and all sets S_n of size n. Then for any n\geq1 and any \delta \in
(0,1), the following bound holds with probability at least 1-\delta over the random draw of the
sample S_n:

	       `|R_{true}(A,S_n) - ^R(A,S_n)| \leq 2\alpha_n + (4n\alpha_n + M) \radic(log(2/\delta)/2n)

<<generalizationBoundTheorem>>
Our [[algorithm]] has a generalization bound of 

	       `|R_{true}(A,S_n) - ^R(A,S_n)| \leq 2\alpha_n + (4n\alpha_n + \gamma) \radic(log(2/\delta)/2n)

with probability 1-\delta. It follows from [[RudinLemma2][Rudin et al.'s Lemma 2]] and our [[stabilityTheorem][stability Theorem]]. \diamond


* Le 17 juin

On a commencé à faire des tests numériques. Voici ce qu'il faudrait faire:

 - Etablir une routine de cross-validation afin d'obtenir un \lambda de régularisation
 - Tracer des points de corrélation (R^2 ?) selon la valeur de \lambda
 - Tracer des courbes de stabilité sur plusieurs tests.
 - Tracer des courbes de vrai risque par rapport au risque empirique afin de déterminer
   comment se comporte le modèle.
 - Tracer vis-à-vis ces courbes les bornes théoriques.

Ensuite il faudra commencer à réfléchir sérieusement à la facon dont on peut créer un
portefeuille à plusieurs titres. Il s'agit probablement d'optimiser sur un espace de
matrice, et non pas simplement sur un vecteur q. Par contre la théorie devra être revue en
profondeur afin d'obtenir de nouvelles bornes.

Now how should X^2_max and \rho should be defined in our numerical tests? First off, an
information vector, at least how it as been defined now, is an uncorrelated multivariate
random variable with mean 0. Now we know for a real random variable that with 95%
confidence level, that x will lie within [-1.96, 19.96]. We're interested with X^2_max,
which is ||x||^2_2. First let's suppose p=2, with both coordinates at 1.96. Then we would
have X^2_max = (1.96)^p = (1.96)^2. However does the confidence shrink?

Let's think out loud. I have a first random variable whose value I know with a 95%
confidence interval lies in [-1.96, 1.96]. But each component is unrelated, by
hypothesis. And the probability of two unrelated events is the product of the two
probabilities. 

We can therefore derive a general identity. If \Sigma is diagonal, then with confidence (.95)^p,
the norm of the vector is less than (1.96)^p... TBC


* Le 18 juin

Donc, comment mesurer numériquement la [[uniformStabilityDefinition][stabilité algorithmique]]? Le probleme le plus
évident est qu'il s'agit de maximiser sur D au grand complet. 

* Le 19 juin

Aujourd'hui on travaillera sur les intervalles de confiance, notamment essayer de mieux
quantifier X^2_max.

Rappelons d'abord que X^2_max représente la région dans laquelle, avec probabilité 1-\delta, se
trouvent tous vecteur d'information x. 

Une chose à la fois. Il était question aussi d'établir une routine de cross-validation
afin d'obtenir un \lambda^\star optimal de régularisation. Voici les étapes qu'elle devrait
réaliser:

  1. On fixe un vecteur de transformation t \in R^p. On fixe aussi un ensemble d'entraînement
     S_n et un ensemble de test S_m à partir de t.
  2. On fixe \lambda = 0.
  3. On résout q^\star à partir de S_n. On conserve le coût total de l'ensemble dans un
     vecteur de résultat c_in.
  4. Avec q^\star, on détermine le cout de l'ensemble S_m qu'on stock dans un vecteur de
     résultat c_out.
  5. On recommence (3) avec \lambda = \lambda + \delta\lambda.
  6. END

					  \diamond \diamond \diamond

_Exploration d'un portefeuille constitué de plusieurs titres._

On considère m-1 titres risqués, et un titre sans risque de rendement R_f. Chacun de ces
titres et composé d'un vecteur d'information x_st, ie. de m ensembles d'informations S_n sur
n jours. 

On souhaite encore former une décision linéaire par rapport à l'information disponible. On
avait donc une application q (ou un algorithme) qui à partir d'un vecreur d'information x
permettait de rendre un portefeuille de la forme [p, 1-p]. Autrement dit, on obtenait un
scalaire à partir duquel l'ensemble du portefeuille était bien défini. Maintenant ce dont
on a besoin, c'est d'un portefeuille vecteur. 

Réfléchissons. A tous les jours on n'a non plus un seul vecteur d'information x, mais bien
une matrice d'information X dont chaque rangée représente un titre et chaque colonne
représente une information quelconque, ie. pour chaque titre s dont on a un vecteur
colonne d'information x_s, on a maintenant une matrice définie par

			       X = [x_1 \cdot\cdot\cdot x_{s}]

On doit donc définir un vecteur de décision q \in R^s tel que Xs rend un vecteur de
portefeuille a s éléments. Le rendement de ce portefeuille sera alors donné par r^{T}Xs, où r
est le vecteur de rendement à cette journée donnée. 

A present, comment déterminer la quantité à investir dans le titre sans risque?
Puisqu'auparavant on allouait la quantité restante (ie. 1 - q^{T}x) au titre sans risque, il
s'agit finalement de faire la même chose ici, ie. 1^{T}Xs donne la composition totale dans
les titres risqués, alors 1 - 1^{T}Xq donnera l'allocation sans risque, de sorte que le
rendement total deviendra:

				   r^{T}Xq + (1 - 1^{T}Xq)R_f

A partir de ce nouveau portefeuille, on peut sans doute utiliser les mêmes outils
développés auparavant, ie. pour le portefeuille à un seul titre. Voyons voir...

_Coût et _Perte._

On a auparavant défini notre fonction de perte (loss) \ell comme étant une fonction prenant
comme argument un algorithme déterminé à partir d'un dataset S_n et un vecteur
d'information complète d=(x,r) \in R^{p+1} pour en retourner le coût total. Le coût était quant
à lui déterminé à partir de l'utilité concave U. 

Le coût a été défini de facon très naïve, puisque qu'on a déterminé que si le rendement du
titre risqué était supérieur au rendement sans risque, alors on s'attendait (ou du moins
on voulait privilégier) un portefeuille constitué uniquement du titre risqué, ie. q^{T}x
\geq 1. Si au contraire le rendement était inférieur au titre sans risque, alors on
s'attendait à ce que le portefeuille soit complètement sans risque, ie. q^{T}x \leq 0. 

Est-ce qu'on pourrait dès lors avoir un coût total qui serait une somme des coûts
individuels pour chaque titre? En fait ce n'est pas nécessaire car on obtient déjà un
rendement du portefeuille scalaire auquel on peut simplement appliquer la même logique que
précédemment. 

Ce sera donc c(p,r), où p et r sont les valeurs vectorielles d'allocation et de rendement,
ie. p = Xq. Mais ce n'est pas si clair... Car supposons que tous les titres donnent un
rendement inférieur à R_f, sauf un. Alors on veut clairement que le portefeuille soit
constitué uniquement de ce titre, et de rien dans le reste. le coût serait donc 

			    \lfloor{}U(max r) - U(r^{T}p + (1 - 1^{T}p)R_f)\rfloor

si max r > R_f.

Au contraire, si max r < R_f, alors le coût deviendra 

			   \lfloor{}U(R_f) - U(r^{T}p + (1 - 1^{T}p)R_f)\rfloor.

Il faut donc à présent revérifier les preuves afin de s'assurer que tout fonctionne. 

On peut toutefois énoncer un nouvel algorithme. On chercherait vraisemblablement à une
fois de plus minimiser le cout total sur un dataset S_{n\times{}s}.

	          q^\star = argmin_{q \in R^p} 1/n \sum_i^n c(Xq, r) + \lambda||q||_2.


